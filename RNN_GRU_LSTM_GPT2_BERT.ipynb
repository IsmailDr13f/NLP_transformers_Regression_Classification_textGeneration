{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7e501b-3b1b-45fb-8e0c-7de022cc94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.2.2\n",
    "#pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/test/cu118\n",
    "#pip install qalsadi\n",
    "#!pip install --upgrade gensim\n",
    "#!pip install --upgrade scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f0cbe3-631e-436f-b7e9-5a87b2820a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "#!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47de4c0f-e013-4569-9711-691f88d1b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Ensuring PyTorch uses the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d6520c-d6bd-49c4-b2b4-8828c2ef6599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d7422-52d3-45de-98a0-7b217ad1afba",
   "metadata": {},
   "source": [
    "# NLP language models using Pytorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2ae1a-bf47-4f10-b94e-a0cfed104ff0",
   "metadata": {},
   "source": [
    "***Objective:*** The primary aim of this lab is to gain familiarity with NLP language models using the PyTorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25ad8b-5604-4e70-893d-667053413a63",
   "metadata": {},
   "source": [
    "### Part1: Deep learning (Regression case):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1432d-aaf2-498a-8e1b-0d9024bb2159",
   "metadata": {},
   "source": [
    "#### #DATA collection (scrapping using beautifulSoup):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a651709c-0ab6-48e2-8ec1-3363209d2515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import requests\\nfrom bs4 import BeautifulSoup\\n\\nurl = \"https://www.aljazeera.net/news/\"\\nheaders = {\\n    \\'User-Agent\\': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"\\n}\\n\\ntry:\\n    session = requests.Session()\\n    r = session.get(url, headers=headers, timeout=10)  \\n    r.raise_for_status()  \\n    soup = BeautifulSoup(r.content, \\'html.parser\\')\\n    div_content = soup.find(\\'div\\', attrs={\\'class\\':\"l-col l-col--8\"})\\n    #print(div_content.prettify())  \\n    articles = div_content.find_all(\\'article\\')\\n    text = []\\n    for article in articles:\\n        title_= article.find(\\'h3\\')\\n        news_= article.find(\\'div\\',attrs={\\'class\\':\\'gc__body-wrap\\'})\\n        if title_ and news_:\\n            text.append(title_.get_text().strip().replace(\\'،\\',\\'\\')+\\' \\'+news_.get_text().strip())\\n\\n    \\nexcept requests.exceptions.RequestException as e:\\n    print(f\"Une erreur s\\'est produite : {e}\")\\n\\n#text\\nscore = [5,8,9,2,8,2.5,8.5,5.8,9,7]\\n\\ndata = {\\n    \\'text\\': text,\\n    \\'score\\': score\\n}\\n\\n#save scraped data in mongodb\\nfrom pymongo import MongoClient\\nclient = MongoClient(\"mongodb://localhost:27017\")\\ndb = client[\\'lab4\\']\\ncollection = db[\\'scraped_col\\']\\ncollection.insert_one(data)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.aljazeera.net/news/\"\n",
    "headers = {\n",
    "    'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    session = requests.Session()\n",
    "    r = session.get(url, headers=headers, timeout=10)  \n",
    "    r.raise_for_status()  \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    div_content = soup.find('div', attrs={'class':\"l-col l-col--8\"})\n",
    "    #print(div_content.prettify())  \n",
    "    articles = div_content.find_all('article')\n",
    "    text = []\n",
    "    for article in articles:\n",
    "        title_= article.find('h3')\n",
    "        news_= article.find('div',attrs={'class':'gc__body-wrap'})\n",
    "        if title_ and news_:\n",
    "            text.append(title_.get_text().strip().replace('،','')+' '+news_.get_text().strip())\n",
    "\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Une erreur s'est produite : {e}\")\n",
    "\n",
    "#text\n",
    "score = [5,8,9,2,8,2.5,8.5,5.8,9,7]\n",
    "\n",
    "data = {\n",
    "    'text': text,\n",
    "    'score': score\n",
    "}\n",
    "\n",
    "#save scraped data in mongodb\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['lab4']\n",
    "collection = db['scraped_col']\n",
    "collection.insert_one(data)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bc368-ed54-42f7-9ff4-521b035cb963",
   "metadata": {},
   "source": [
    "#### #NOTE: We'll create a table with two columns: the first column will contain the scraped text, and the second column will display the score, which I will assign based on the importance of the information to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff6d779-8995-4bf7-b0d8-15c488e50e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0\n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0\n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0\n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0\n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0\n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5\n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5\n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8\n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0\n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['lab4']\n",
    "collection = db['scraped_col']\n",
    "#use this data\n",
    "all_documents = collection.find()\n",
    "\"\"\"for document in all_documents:\n",
    "    print(document)\"\"\"\n",
    "\n",
    "single_document = collection.find_one({'score': [5, 8, 9, 2, 8, 2.5, 8.5, 5.8, 9, 7]})\n",
    "#print(single_document)\n",
    "\n",
    "dataa = {'text':single_document['text'], 'score':single_document['score']}\n",
    "df = pd.DataFrame(dataa)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74e462-e505-496f-8855-9a3e7c982623",
   "metadata": {},
   "source": [
    "#### #Preprocessing NLP pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4964c629-5a7b-407e-8f4d-ff070eec964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df070bc4-1592-4bdf-9429-ef0c3930f96d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0   \n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0   \n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0   \n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0   \n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0   \n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5   \n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5   \n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8   \n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0   \n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...  \n",
       "1  [إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...  \n",
       "2  [حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...  \n",
       "3  [ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...  \n",
       "4  [“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...  \n",
       "5  [الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...  \n",
       "6  [(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...  \n",
       "7  [مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...  \n",
       "8  [الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...  \n",
       "9  [إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# tokenize the text\n",
    "tokens_=[nltk.word_tokenize(txt) for txt in df['text']]\n",
    "# insert into df    \n",
    "df.insert(2,'tokens',tokens_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7841be1-17df-46f3-bbbc-2d05dc2aaa27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...</td>\n",
       "      <td>[رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...</td>\n",
       "      <td>[رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...</td>\n",
       "      <td>[حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...</td>\n",
       "      <td>[رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...</td>\n",
       "      <td>[“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...</td>\n",
       "      <td>[تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...</td>\n",
       "      <td>[(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...</td>\n",
       "      <td>[سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...</td>\n",
       "      <td>[تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...</td>\n",
       "      <td>[علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0   \n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0   \n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0   \n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0   \n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0   \n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5   \n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5   \n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8   \n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0   \n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...   \n",
       "1  [إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...   \n",
       "2  [حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...   \n",
       "3  [ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...   \n",
       "4  [“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...   \n",
       "5  [الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...   \n",
       "6  [(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...   \n",
       "7  [مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...   \n",
       "8  [الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...   \n",
       "9  [إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...   \n",
       "\n",
       "                                            stemmers  \n",
       "0  [رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...  \n",
       "1  [رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...  \n",
       "2  [حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...  \n",
       "3  [رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...  \n",
       "4  [“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...  \n",
       "5  [تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...  \n",
       "6  [(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...  \n",
       "7  [سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...  \n",
       "8  [تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...  \n",
       "9  [علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming in arabic\n",
    "#nltk.download()\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "stemmer = ISRIStemmer()\n",
    "stemmers_=[[ stemmer.stem(wrd) for wrd in row]for row in df['tokens']]\n",
    "df.insert(3,'stemmers',stemmers_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9b965f-9a43-4367-9198-176b2e8358ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmers</th>\n",
       "      <th>lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...</td>\n",
       "      <td>[رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...</td>\n",
       "      <td>[استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...</td>\n",
       "      <td>[رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...</td>\n",
       "      <td>[إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...</td>\n",
       "      <td>[حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...</td>\n",
       "      <td>[حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...</td>\n",
       "      <td>[رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...</td>\n",
       "      <td>[ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...</td>\n",
       "      <td>[“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...</td>\n",
       "      <td>[“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...</td>\n",
       "      <td>[تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...</td>\n",
       "      <td>[اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...</td>\n",
       "      <td>[(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...</td>\n",
       "      <td>[(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...</td>\n",
       "      <td>[سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...</td>\n",
       "      <td>[مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...</td>\n",
       "      <td>[تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...</td>\n",
       "      <td>[اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...</td>\n",
       "      <td>[علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...</td>\n",
       "      <td>[إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0   \n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0   \n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0   \n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0   \n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0   \n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5   \n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5   \n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8   \n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0   \n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...   \n",
       "1  [إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...   \n",
       "2  [حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...   \n",
       "3  [ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...   \n",
       "4  [“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...   \n",
       "5  [الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...   \n",
       "6  [(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...   \n",
       "7  [مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...   \n",
       "8  [الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...   \n",
       "9  [إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...   \n",
       "\n",
       "                                            stemmers  \\\n",
       "0  [رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...   \n",
       "1  [رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...   \n",
       "2  [حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...   \n",
       "3  [رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...   \n",
       "4  [“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...   \n",
       "5  [تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...   \n",
       "6  [(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...   \n",
       "7  [سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...   \n",
       "8  [تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...   \n",
       "9  [علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...   \n",
       "\n",
       "                                          lemmatizer  \n",
       "0  [استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...  \n",
       "1  [إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...  \n",
       "2  [حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...  \n",
       "3  [ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...  \n",
       "4  [“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...  \n",
       "5  [اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...  \n",
       "6  [(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...  \n",
       "7  [مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...  \n",
       "8  [اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...  \n",
       "9  [إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qalsadi.lemmatizer as lm\n",
    "\n",
    "lemmer = lm.Lemmatizer()\n",
    "lemmatizer_=[[ lemmer.lemmatize(wrd) for wrd in row]for row in df['tokens']]\n",
    "df.insert(4,'lemmatizer',lemmatizer_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70feddac-c68b-49e0-8c49-185f1b073579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmers</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>stop_wrds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...</td>\n",
       "      <td>[رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...</td>\n",
       "      <td>[استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...</td>\n",
       "      <td>[استمرار, قتال, فاشر, فرار, آلاف, هجوم, دعم, س...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...</td>\n",
       "      <td>[رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...</td>\n",
       "      <td>[إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...</td>\n",
       "      <td>[إنترسبت, :, منظم, أميركية, ``, ربح, '', تمول,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...</td>\n",
       "      <td>[حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...</td>\n",
       "      <td>[حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...</td>\n",
       "      <td>[حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...</td>\n",
       "      <td>[رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...</td>\n",
       "      <td>[ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...</td>\n",
       "      <td>[ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...</td>\n",
       "      <td>[“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...</td>\n",
       "      <td>[“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...</td>\n",
       "      <td>[“, واد, حي, ”, .., موطن, حوت, مشى, أقدامهExte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...</td>\n",
       "      <td>[تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...</td>\n",
       "      <td>[اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...</td>\n",
       "      <td>[اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...</td>\n",
       "      <td>[(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...</td>\n",
       "      <td>[(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...</td>\n",
       "      <td>[(, شاهد, ), قبيل, عراة, .., صنع, خبز, شجر, سا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...</td>\n",
       "      <td>[سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...</td>\n",
       "      <td>[مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...</td>\n",
       "      <td>[مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...</td>\n",
       "      <td>[تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...</td>\n",
       "      <td>[اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...</td>\n",
       "      <td>[اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...</td>\n",
       "      <td>[علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...</td>\n",
       "      <td>[إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...</td>\n",
       "      <td>[إعلام, إسرائيلي, :, جيش, أخفق, اغتيال, قائد, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0   \n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0   \n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0   \n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0   \n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0   \n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5   \n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5   \n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8   \n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0   \n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...   \n",
       "1  [إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...   \n",
       "2  [حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...   \n",
       "3  [ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...   \n",
       "4  [“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...   \n",
       "5  [الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...   \n",
       "6  [(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...   \n",
       "7  [مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...   \n",
       "8  [الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...   \n",
       "9  [إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...   \n",
       "\n",
       "                                            stemmers  \\\n",
       "0  [رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...   \n",
       "1  [رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...   \n",
       "2  [حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...   \n",
       "3  [رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...   \n",
       "4  [“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...   \n",
       "5  [تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...   \n",
       "6  [(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...   \n",
       "7  [سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...   \n",
       "8  [تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...   \n",
       "9  [علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...   \n",
       "\n",
       "                                          lemmatizer  \\\n",
       "0  [استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...   \n",
       "1  [إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...   \n",
       "2  [حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...   \n",
       "3  [ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...   \n",
       "4  [“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...   \n",
       "5  [اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...   \n",
       "6  [(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...   \n",
       "7  [مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...   \n",
       "8  [اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...   \n",
       "9  [إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...   \n",
       "\n",
       "                                           stop_wrds  \n",
       "0  [استمرار, قتال, فاشر, فرار, آلاف, هجوم, دعم, س...  \n",
       "1  [إنترسبت, :, منظم, أميركية, ``, ربح, '', تمول,...  \n",
       "2  [حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...  \n",
       "3  [ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...  \n",
       "4  [“, واد, حي, ”, .., موطن, حوت, مشى, أقدامهExte...  \n",
       "5  [اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...  \n",
       "6  [(, شاهد, ), قبيل, عراة, .., صنع, خبز, شجر, سا...  \n",
       "7  [مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...  \n",
       "8  [اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...  \n",
       "9  [إعلام, إسرائيلي, :, جيش, أخفق, اغتيال, قائد, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords:\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('arabic')\n",
    "#print(stopwords_list)\n",
    "rm_stpwrds_=[[wrd for wrd in row if wrd not in stopwords_list] for row in df['lemmatizer']]\n",
    "df.insert(5,'stop_wrds',rm_stpwrds_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4189fe-7b4c-43fb-b3cd-268181266bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmers</th>\n",
       "      <th>lemmatizer</th>\n",
       "      <th>stop_wrds</th>\n",
       "      <th>wrd2vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...</td>\n",
       "      <td>[رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...</td>\n",
       "      <td>[استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...</td>\n",
       "      <td>[استمرار, قتال, فاشر, فرار, آلاف, هجوم, دعم, س...</td>\n",
       "      <td>[[-0.0017053209, 0.0007461346, -0.0017587369, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...</td>\n",
       "      <td>[رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...</td>\n",
       "      <td>[إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...</td>\n",
       "      <td>[إنترسبت, :, منظم, أميركية, ``, ربح, '', تمول,...</td>\n",
       "      <td>[[0.0010913523, 0.0006159678, -0.00014685951, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...</td>\n",
       "      <td>[حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...</td>\n",
       "      <td>[حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...</td>\n",
       "      <td>[حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...</td>\n",
       "      <td>[[-0.0011092921, -0.00052361906, -3.1844247e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...</td>\n",
       "      <td>[رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...</td>\n",
       "      <td>[ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...</td>\n",
       "      <td>[ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...</td>\n",
       "      <td>[[0.00027223802, 0.00056331966, 0.0002675695, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...</td>\n",
       "      <td>[“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...</td>\n",
       "      <td>[“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...</td>\n",
       "      <td>[“, واد, حي, ”, .., موطن, حوت, مشى, أقدامهExte...</td>\n",
       "      <td>[[-0.006838454, 0.008972532, -0.003979155, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...</td>\n",
       "      <td>[تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...</td>\n",
       "      <td>[اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...</td>\n",
       "      <td>[اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...</td>\n",
       "      <td>[[0.001711613, -0.00038293132, 0.0026010964, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...</td>\n",
       "      <td>[(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...</td>\n",
       "      <td>[(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...</td>\n",
       "      <td>[(, شاهد, ), قبيل, عراة, .., صنع, خبز, شجر, سا...</td>\n",
       "      <td>[[0.004020752, 0.0007369402, 0.003895934, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...</td>\n",
       "      <td>[سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...</td>\n",
       "      <td>[مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...</td>\n",
       "      <td>[مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...</td>\n",
       "      <td>[[-0.00044712992, -0.0017695747, 0.0020613454,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...</td>\n",
       "      <td>[تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...</td>\n",
       "      <td>[اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...</td>\n",
       "      <td>[اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...</td>\n",
       "      <td>[[0.001711613, -0.00038293132, 0.0026010964, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...</td>\n",
       "      <td>[علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...</td>\n",
       "      <td>[إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...</td>\n",
       "      <td>[إعلام, إسرائيلي, :, جيش, أخفق, اغتيال, قائد, ...</td>\n",
       "      <td>[[-0.00045498088, -0.0022565406, 0.0002150855,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  استمرار القتال بالفاشر وفرار الآلاف بعد هجوم ا...    5.0   \n",
       "1  إنترسبت: منظمة أميركية \"غير ربحية\" تموّل وحدة ...    8.0   \n",
       "2  حزب الله يستهدف مواقع إسرائيلية ونصر الله يتوع...    9.0   \n",
       "3  ترحيب فلسطيني ودولي بقرار \"العدل الدولية\" وقف ...    2.0   \n",
       "4  “وادي الحيتان”.. موطن الحوت الذي يمشي على أقدا...    8.0   \n",
       "5  الاتحاد الأوروبي يدرس إمكانية إرسال بعثة حدودي...    2.5   \n",
       "6  (شاهد) قبيلة العراة.. كيف يصنعون الخبز من شجرة...    8.5   \n",
       "7  مسيرات عربية دعما لصمود المقاومة بغزة انطلقت ا...    5.8   \n",
       "8  الاتحاد الأوروبي يعدّل قواعد شنغن تبنى الاتحاد...    9.0   \n",
       "9  إعلام إسرائيلي: الجيش يخفق في اغتيال قائد لواء...    7.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [استمرار, القتال, بالفاشر, وفرار, الآلاف, بعد,...   \n",
       "1  [إنترسبت, :, منظمة, أميركية, ``, غير, ربحية, '...   \n",
       "2  [حزب, الله, يستهدف, مواقع, إسرائيلية, ونصر, ال...   \n",
       "3  [ترحيب, فلسطيني, ودولي, بقرار, ``, العدل, الدو...   \n",
       "4  [“, وادي, الحيتان, ”, .., موطن, الحوت, الذي, ي...   \n",
       "5  [الاتحاد, الأوروبي, يدرس, إمكانية, إرسال, بعثة...   \n",
       "6  [(, شاهد, ), قبيلة, العراة, .., كيف, يصنعون, ا...   \n",
       "7  [مسيرات, عربية, دعما, لصمود, المقاومة, بغزة, ا...   \n",
       "8  [الاتحاد, الأوروبي, يعدّل, قواعد, شنغن, تبنى, ...   \n",
       "9  [إعلام, إسرائيلي, :, الجيش, يخفق, في, اغتيال, ...   \n",
       "\n",
       "                                            stemmers  \\\n",
       "0  [رار, قتل, فشر, فرر, الف, بعد, هجم, دعم, سرع, ...   \n",
       "1  [رسب, :, نظم, امر, ``, غير, ربح, '', تمل, وحد,...   \n",
       "2  [حزب, الل, هدف, وقع, اسرائيلية, نصر, الل, وعد,...   \n",
       "3  [رحب, لسط, ودل, قرر, ``, عدل, دول, '', وقف, عد...   \n",
       "4  [“, ودي, حيت, ”, .., وطن, حوت, الذي, يمش, على,...   \n",
       "5  [تحد, ورب, درس, مكن, رسل, بعث, حدد, الى, رفح, ...   \n",
       "6  [(, شهد, ), قبل, عرة, .., كيف, صنع, خبز, من, ش...   \n",
       "7  [سير, عرب, دعم, صمد, قام, بغز, طلق, اليوم, جمع...   \n",
       "8  [تحد, ورب, عدل, قعد, شنغ, بنى, تحد, روبي،, الي...   \n",
       "9  [علم, اسرائيلي, :, جيش, خفق, في, غيل, قئد, لوء...   \n",
       "\n",
       "                                          lemmatizer  \\\n",
       "0  [استمرار, قتال, فاشر, فرار, آلاف, بعد, هجوم, د...   \n",
       "1  [إنترسبت, :, منظم, أميركية, ``, غير, ربح, '', ...   \n",
       "2  [حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...   \n",
       "3  [ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...   \n",
       "4  [“, واد, حي, ”, .., موطن, حوت, الذي, مشى, على,...   \n",
       "5  [اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...   \n",
       "6  [(, شاهد, ), قبيل, عراة, .., كيف, صنع, خبز, من...   \n",
       "7  [مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...   \n",
       "8  [اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...   \n",
       "9  [إعلام, إسرائيلي, :, جيش, أخفق, في, اغتيال, قا...   \n",
       "\n",
       "                                           stop_wrds  \\\n",
       "0  [استمرار, قتال, فاشر, فرار, آلاف, هجوم, دعم, س...   \n",
       "1  [إنترسبت, :, منظم, أميركية, ``, ربح, '', تمول,...   \n",
       "2  [حزب, الله, استهدف, مواقع, إسرائيلية, نصر, الل...   \n",
       "3  [ترحيب, فلسطين, دولي, قرار, ``, عدل, دولي, '',...   \n",
       "4  [“, واد, حي, ”, .., موطن, حوت, مشى, أقدامهExte...   \n",
       "5  [اتحاد, أوروبي, درس, إمكان, إرسال, بعثة, حدود,...   \n",
       "6  [(, شاهد, ), قبيل, عراة, .., صنع, خبز, شجر, سا...   \n",
       "7  [مسير, عرب, دعم, صمود, مقاوم, غزة, انطلق, يوم,...   \n",
       "8  [اتحاد, أوروبي, عدل, قواعد, شنغن, بنى, اتحاد, ...   \n",
       "9  [إعلام, إسرائيلي, :, جيش, أخفق, اغتيال, قائد, ...   \n",
       "\n",
       "                                            wrd2vect  \n",
       "0  [[-0.0017053209, 0.0007461346, -0.0017587369, ...  \n",
       "1  [[0.0010913523, 0.0006159678, -0.00014685951, ...  \n",
       "2  [[-0.0011092921, -0.00052361906, -3.1844247e-0...  \n",
       "3  [[0.00027223802, 0.00056331966, 0.0002675695, ...  \n",
       "4  [[-0.006838454, 0.008972532, -0.003979155, -0....  \n",
       "5  [[0.001711613, -0.00038293132, 0.0026010964, 0...  \n",
       "6  [[0.004020752, 0.0007369402, 0.003895934, 0.00...  \n",
       "7  [[-0.00044712992, -0.0017695747, 0.0020613454,...  \n",
       "8  [[0.001711613, -0.00038293132, 0.0026010964, 0...  \n",
       "9  [[-0.00045498088, -0.0022565406, 0.0002150855,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "with open('arabic.txt', 'w',encoding='UTF-8') as file:\n",
    "    for row in df['text']:\n",
    "        file.write(row)\n",
    "# Train the model using the skipgram method\n",
    "model = fasttext.train_unsupervised('arabic.txt', model='skipgram', dim=100)\n",
    "wrd2vect_=[[model.get_word_vector(wrd) for wrd in row]for row in df['stop_wrds']]\n",
    "df.insert(6,'wrd2vect',wrd2vect_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312afa81-89a6-4c5f-b84d-d2dc01c9f17e",
   "metadata": {},
   "source": [
    "#### #Train the models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1457b-7f56-4790-bf70-84f840a1c891",
   "metadata": {},
   "source": [
    "##### #RNN(Unidirection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e10bd99-6696-47f7-8398-7842f3d7902d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 40, 100)\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 41.1208\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 38.5797\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 34.4750\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 30.5070\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 28.1895\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 26.5494\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25.0157\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 23.5171\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 22.0767\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 20.7166\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 19.4452\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 18.2618\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.1613\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.1370\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 15.1822\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 14.2907\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.4573\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 12.6778\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 11.9499\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.2722\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 10.6446\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 10.0671\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5397\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.0616\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.6317\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.2482\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9088\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6107\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3511\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.1270\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9353\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7729\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.6370\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.5248\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.4334\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.3605\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3035\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.2603\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.2288\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.2071\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.1935\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.1865\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.1845\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.1865\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.1912\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1977\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2053\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.2132\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.2210\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.2282\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 5.5683\n",
      "Test Loss: 5.5682806968688965\n",
      "1/1 [==============================] - 0s 134ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.1940928],\n",
       "       [6.193499 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "input_dim = 100\n",
    "sequence_length = 40\n",
    "X=df['wrd2vect'].to_numpy()\n",
    "y=df['score'].values\n",
    "\n",
    "padded_sequences = pad_sequences(X, maxlen=40, padding='post', dtype='float32')\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#build RNN\n",
    "model_rnn = Sequential()\n",
    "#Add layers\n",
    "model_rnn.add(SimpleRNN(50, input_shape=(sequence_length, 100)))\n",
    "model_rnn.add(Dense(1))\n",
    "model_rnn.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_rnn.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model_rnn.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_rnn.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions if data was scaled\n",
    "#predictions = scaler.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9a96498-9e86-4e2a-82b0-ad0efd66786b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 8.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac5cfc-a8d7-416c-9b70-240615ca75f2",
   "metadata": {},
   "source": [
    "##### #RNN(Bidirection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c44bc25d-434a-43a8-b87e-641462452110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.5844\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 39.2049\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 35.5599\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 31.3419\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 27.9222\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 24.9777\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 22.4074\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 20.2707\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 18.1598\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.0987\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.2944\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 12.7632\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4488\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.3121\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3355\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.5098\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8269\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2785\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8549\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5448\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3351\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.2115\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1584\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.1602\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.2015\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2678\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3460\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.4251\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4962\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5531\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.5918\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.6108\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.6103\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.5923\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5595\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5156\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4644\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4097\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3551\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3036\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2577\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2190\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1885\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1665\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1527\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.1460\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.1453\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1491\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1558\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1638\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 7.6027\n",
      "Test Loss: 7.602669715881348\n",
      "1/1 [==============================] - 0s 167ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.78808 ],\n",
       "       [5.788912]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build RNN_bi\n",
    "model_rnn_bi = Sequential()\n",
    "#Add layers\n",
    "model_rnn_bi.add(Bidirectional(SimpleRNN(50, input_shape=(sequence_length, 100))))\n",
    "model_rnn_bi.add(Dense(1))\n",
    "model_rnn_bi.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_rnn_bi.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "loss1 = model_rnn_bi.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss1}')\n",
    "\n",
    "# Make predictions\n",
    "predictions1 = model_rnn_bi.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions if data was scaled\n",
    "#predictions = scaler.inverse_transform(predictions)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70302c49-c9fd-4488-89e6-609adf3b5f3e",
   "metadata": {},
   "source": [
    "##### #GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fa2d0f-3130-4a0a-83d3-0d6dd3e0276a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.8919\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 41.6282\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 41.3425\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 41.0207\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.6534\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.2294\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 39.7339\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 39.1467\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 38.4392\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 37.5696\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 36.4733\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 35.0461\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.1051\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.2991\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 25.8734\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.1472\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.0859\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.2234\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 20.7457\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13.2209\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4280\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.8574\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.8850\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.9491\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.4498\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7522\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3560\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4690\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.4716\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7273\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6252\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.5863\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.8295\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.8820\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2661\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.2035\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5259\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9064\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.1103\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.0643\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8207\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.5035\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2485\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1421\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1851\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3099\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4295\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4821\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4506\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3572\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 5.1063\n",
      "Test Loss: 5.106266975402832\n",
      "1/1 [==============================] - 0s 220ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.284831],\n",
       "       [6.314654]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build GRU\n",
    "model_gru = Sequential()\n",
    "#Add layers\n",
    "model_gru.add(GRU(128,return_sequences=False))\n",
    "model_gru.add(Dense(1))\n",
    "model_gru.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_gru.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "loss2 = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss2}')\n",
    "\n",
    "# Make predictions\n",
    "predictions2 = model_gru.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions if data was scaled\n",
    "#predictions = scaler.inverse_transform(predictions)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550cfd-61c4-4e64-94b1-6c469197842f",
   "metadata": {},
   "source": [
    "##### #LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bff7093-4227-4228-b32b-b3341fce1b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.8945\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 41.7077\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 41.4963\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 41.2356\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.8994\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 40.4478\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 39.8070\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.8342\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 37.2331\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 34.3395\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 28.6231\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.6258\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.9366\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.9270\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.2835\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.2224\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.5809\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.7900\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.0797\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.5639\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2743\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1863\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2445\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.3841\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5468\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6895\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.7867\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.8282\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8158\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.7583\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.6691\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.5628\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.4538\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.3545\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2741\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.2184\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1890\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.1838\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1975\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.2228\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2519\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2777\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2948\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.3007\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2951\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2801\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2592\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2361\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2146\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1972\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 6.2624\n",
      "Test Loss: 6.262442588806152\n",
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.0467596],\n",
       "       [6.049806 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build GRU\n",
    "model_lstm = Sequential()\n",
    "#Add layers\n",
    "model_lstm.add(LSTM(128,return_sequences=False))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_lstm.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "loss3 = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss3}')\n",
    "\n",
    "# Make predictions\n",
    "predictions3 = model_lstm.predict(X_test)\n",
    "predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b0500e8-1189-4a97-8c3a-a3b658bd3607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN---------------------------------------\n",
      "Mean Absolute Error (MAE): 2.306204080581665\n",
      "Mean Squared Error (MSE): 5.568280518269262\n",
      "Root Mean Squared Error (RMSE): 2.3597204322269327\n",
      "RNN-BI---------------------------------------\n",
      "Mean Absolute Error (MAE): 2.7115039825439453\n",
      "Mean Squared Error (MSE): 7.602669822244934\n",
      "Root Mean Squared Error (RMSE): 2.757293931057212\n",
      "GRU---------------------------------------\n",
      "Mean Absolute Error (MAE): 2.2002575397491455\n",
      "Mean Squared Error (MSE): 5.1062670046591165\n",
      "Root Mean Squared Error (RMSE): 2.2597050702822075\n",
      "LSTM---------------------------------------\n",
      "Mean Absolute Error (MAE): 2.4517171382904053\n",
      "Mean Squared Error (MSE): 6.262442502798535\n",
      "Root Mean Squared Error (RMSE): 2.502487263263998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def metrics_reg(y_tes, y_pred):\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_tes, y_pred)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    \n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_tes, y_pred)\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    \n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    \n",
    "    \n",
    "\n",
    "preds=[predictions,predictions1,predictions2,predictions3]\n",
    "algos=['RNN','RNN-BI','GRU','LSTM']\n",
    "for i in range(4):\n",
    "    print(algos[i]+'---------------------------------------')\n",
    "    metrics_reg(y_test,preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14b95e-ded2-4555-9687-cd6514cb01ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5618d468-0b04-471d-9386-62f1d443996f",
   "metadata": {},
   "source": [
    "### Part2: Transformer (Text generation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c48ba48-6ffb-4dea-a8ca-a427d8a40975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ce4016-292a-41fb-adb3-429936400564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "312a9f85-6a8e-480d-b706-8dff0e0330bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aaca14b-9357-4596-a72c-a013bed0a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3695e747-9eeb-47ad-8225-e9a0dd59d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to first select top n tokens from the probability list and then based on the selected n word distribution\n",
    "# get random token ID\n",
    "def choose_best_n(probs,n):\n",
    "    indx= np.argpartition(probs,-n)[-n:]\n",
    "    best_probs=probs[indx]\n",
    "    best_probs/=np.sum(best_probs)\n",
    "    choice = np.random.choice(n,1,p=best_probs)\n",
    "    token_id=indx[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0ae61f8-c665-4771-a0e3-dc2d98265c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "class SciFiDataset(Dataset):\n",
    "    def __init__(self, story_path='_data/'):\n",
    "        super().__init__()\n",
    "        scifi_path = os.path.join(story_path, 'stories.txt')\n",
    "\n",
    "        self.story_list = []\n",
    "        self.end_of_token = \"<|endoftext|>\"\n",
    "\n",
    "        with open(scifi_path, 'r', encoding='UTF-8') as txt_file:\n",
    "            content = txt_file.read()\n",
    "\n",
    "            # Split the content into individual stories using the end-of-text marker\n",
    "            stories = content.split('-END OF TEXT-')\n",
    "\n",
    "            for story in stories:\n",
    "                # Remove newlines within the story and strip leading/trailing spaces\n",
    "                cleaned_story = story.replace('\\n', '').strip()\n",
    "                #cleaned_story = cleaned_story.replace('*','').lower()\n",
    "                \n",
    "                story_str = f\"STORY: {cleaned_story}{self.end_of_token}\"\n",
    "                self.story_list.append(story_str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.story_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.story_list[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "544b3cb0-ce9f-4f1b-a5ce-cbbd65f70f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 stories from story_list:\n",
      "STORY: All in due time.  When our plane landed and I disembarked, the Miami International Airport looked *so* strange, and the people that stopped in their tracks to stare at us in utter shock were confusing me.  The clothes people were wearing looked odd, and the women did not wear hats, gloves...and what a disgrace, the women were not wearing dresses but embarrassing themselves and parading around in pants like *men*??  I was hungry, *so, so hungry*, and though my husband said he would be waiting, I didn't see him, so I walked to the nearest food stand, a new place I had never seen called \"Cinnabon\", ignoring that the woman in front of me looked back at me, then ran out of line, dragging her young son with her.  I got in line, hearing screams in the airport, and as I looked over at a newsstand, I saw with unbelieving eyes the date on a magazine was June 1, 2021--our plane was Airliner NC16002, leaving Puerto Rico heading to Miami on December 28, 1948, a direct flight over the Bermuda Triangle--what *sick* joke was this, then I glanced at my reflection in a mirror and understood.<|endoftext|>\n",
      "STORY: Millionaire.  When my checking account registered $1,500,853 on Tuesday afternoon when I checked it before leaving for lunch, I thought it was a glitch with my app, so I refreshed it, but it still read the same balance.  I only had $853 in the account just this morning, and my account history didn't show any transfer or deposit of $1,500,000, which made it more strange--no record of it arriving in my account.  I called the bank and they confirmed the same balance I saw on my app, and after I hung up, I sat dumbfounded in my office chair, a mixture of growing happiness and worry, trying to figure how what the heck was going on.  A text message suddenly appeared under PRIVATE NUMBER: \"The police will be told that you hacked $1,500,000 from the Community Bank of Lillville if you don't meet me in 10 minutes in your office building lobby, complete the task I will give you (I will be wearing a red hat) and destroy this phone when you are done reading this...we are watching.\"<|endoftext|>\n",
      "STORY: LIVE ON THE SCENE!  \"Thats right, Kelly, if you look just over my shoulder there you can see the sinkhole itself stretching nearly four city blocks!  In fact, if you follow me a moment, you can see climbers behind the barrier preparing to rapel into the - oh, here they go!  Now, the tremors have been one thing, Kelly, but not a single body has been recovered yet, even from the more accessible sections of t- oh it looks like the climbers are already returning!  Hold on, there seems to be some commotion - yes it seems the rescuers have recovered several bodies... No, no... That's one body... Cut it, cut the feed, cut the feed now!\"<|endoftext|>\n",
      "STORY: The New Kid  There was something off about the new kid in our high school--and not counting the annoying black goth clothing, the piercings and spike jewelry--there was definitely something weird about the way he looked at everyone.  Sitting at the desk behind Goth Boy during math class, I wondered whether he had any brothers or sisters who also dressed--he turned around suddenly and said quietly, \"No, I'm an only child.\"  He turned back around to listen to the teacher, and I froze, my eyes wide with shock and I wondered if I had accidently said what I was thinking out loud.  He turned back *again* and whispered, \"No, you didn't accidently say out loud if you wondered if I had brothers or sisters, I can read minds--and the whole Goth Boy thing you call me in your head is super annoying, so please just use my name, it's Matt, and it's nice to meet you.\"<|endoftext|>\n",
      "STORY: Seven  Seven.   How can such a boring number be so frightening?   *Seven*.   Seven months to go.<|endoftext|>\n",
      "STORY: Rot  I’ve been dead for a long time now.   I have been diagnosed with a multitude of illnesses and stuffed full of pills, but no one will listen when I tell them why they don’t work.  I am rotting from the inside out, there are black worms squirming under my skin and my bone marrow has turned to dust.    I can barely move, or think, or speak, and I can’t wait until I lose these abilities entirely.<|endoftext|>\n",
      "STORY: Click.  The constant *click, click, click* of the calculator keys as I do math grates my nerves, reminds me of the incessant, irritating, tapping of a woodpecker on a tree.  Being the senior Certified Public Accountant assigned to many huge finance contracts requires putting in long hours on that damn calculator.  Fortunately for me, I quit my job yesterday.  Today, the constant *click, click, click* of the calculator keys as I add the millions of dollars I've stolen from those huge finance contracts over 22 years is the sweetest sound in the world.<|endoftext|>\n",
      "STORY: Extinction.  I pushed the pod doors open, leaving my partner and raced upstairs to unlock the sewer drain cover, and to my joy, I didn't see a wasteland, but a city bustling with life--did we *finally* change our fate and save our future?  Looking frantically around for signs of the creatures, I ran up to the first person I saw with a phone and asked, \"Can I please borrow your phone--I have to see if we caused them to go extinct, because if  not, we're as good as dead,\" my voice trembling.  With an amused look, the guy handed me his phone and I searched *'are dinosaurs extinct'* and read the first result with relief, \"The last dinosaurs died approximately 65 million years ago, dying out soon after a huge meteorite crashed to Earth near the Gulf of Mexico.\"  The time travel mission worked after ***so*** many attempts, I thought, crying with happiness--what history recorded as \"meteorites\" were actually atomic bombs we used to wipe out the wretched lizards in order to save humanity from the many centuries of reptilian war that had plagued us.<|endoftext|>\n",
      "STORY: Coco.  The cat I brought home from the Ralcon Veterinary Hospital after a three day stay is not my cat.  He looks like Coco but doesn't act like him--he doesn't meow, doesn't let me pet him, doesn't rub against my legs, or lay next to my pillow at night like Coco used to.  This new Coco doesn't eat or drink, it only follows me from room to room, sitting one foot away only to stare at me, its green eyes never blinking or wavering eye contact.  It's now been two weeks of this odd behavior, and realizing my old Coco will never return, I decided this new Coco was too scary to keep, so I got the cat carrier and as I went to grab it to put it inside, \"Coco\" backed up quickly, defiantly sat back down, looked me in the eyes and said in an deep, otherworldly voice \"I am not going anywhere.\"<|endoftext|>\n",
      "STORY: The ocean.    She finally got to the water's edge, placing her left foot into the cold ocean water, then slowly putting her right foot in, watching the wet sand softly wrap itself around her feet, welcoming her.  The beachgoers were long gone, and the moonlight was reflecting off the water only for small fragments of time as the clouds playing a heavenly tug-of-war as to who had the right to be seen in the night sky.  She walked deeper, deeper, toward the depths ahead, and as the water lapped around her neck, she involuntary shivered from the frigid temperatures, panic rising from deep inside, making her jump back, again and back even more, her arms flailing, until the water was only at her knees.  Crying, she turned and walked back to the shore, she couldn't do it, but what was the other option, just living with the pain?<|endoftext|>\n",
      "STORY: ?  He preferred the quiet and calm of night, she loved the brightness and buzz of people during the day.  She loved big family gatherings and trying new foods, while he would rather stay home every weekend and eat nothing but spaghetti or hot dogs.  She sat there for what felt like hours, looking back and forth from the engagement ring to his handsome, worried brown eyes.  He had alerted everyone in the restaurant and they cheered when he popped the question, but it was becoming uncomfortably clear to all involved that her answer was going to be no.<|endoftext|>\n",
      "STORY: The Breville.  The big stuff has all been divided at the divorce settlement--the furniture, art, camping equipment, books and various other \"sundries\".  Passing through the kitchen to grab an empty moving box from the den, I stopped suddenly, glancing at the $900 Breville Barista Pro espresso maker and realizing we forgot to decide who takes it.  Listening to make sure he wasn't coming downstairs, I quickly grabbed a trash bag, stuffed the espresso maker in it and ran it to my SUV and buried it under an old Green Bay Packers picnic blanket in the back.  I hated espresso drinks--but damn if I was going to let him and his *new* woman enjoy them.<|endoftext|>\n",
      "STORY: The Professor    I just killed my professor.  We were alone in the classroom, I needed help with homework, but he was **too** close, he kept touching my back and arms.  I was uncomfortable, I kept moving away, but he kept getting closer, and when his hand touched my butt I screamed for him to stop and pushed him hard, *too* hard.  He lost his balance and hit his head on the corner of his desk and he's on the floor not moving--what the hell do I do now?<|endoftext|>\n",
      "STORY: Catch and Release.  Fishing here alone always brought me peace, I found people were a nuisance, they lied, were rude, ungrateful and selfish.  Other men liked to hunt, but I could never bear the thought of killing anything, even fish--I always released them once they got on my hook.  Killing was an awful thing, which is why my girlfriend's ex-boyfriend was still alive.  He was safely tied up in my shed at home, and even though he had asked her to get back together with him, I won't kill him, he will just stay in there unharmed until he changes his mind.<|endoftext|>\n",
      "STORY: The Talk.  \"So, basically, that's how your body changes in your teens and how reproduction works, you know in a basic way,\" my Dad said awkwardly, \"And remember, you can always talk to me about anything--do you have any questions?\"  \"Oh, no, no, I understand everything, we are definitely done with this discussion,\" I said, jumping up from my bed, \"I'm still not sure why you needed to draw diagrams of everything,\" I said, waving my hand over the sea of horrifically drawn images of male and female body parts, some of them engaged in well, let's just say forms of \"reproduction.\"  \"Omer, I don't want you looking at porn to see the images we talked about, the internet can guide in you in directions that aren't good,\" he said and starting to gather them up, \"Oh wait, not unless, do you want to keep these?\"  \"Oh no, Dad, please take them away,\" I said, quickly helping him pick up the pictures and trying not to laugh, knowing that even though it was one of the most awkward hours I had spent with him, I was reminded of the great relationship we had, and it was an experience I would probably have with my own son one day--minus the pictures.<|endoftext|>\n",
      "STORY: Just. Don't. Fall.  The 'Challenge Club' started a *Just.Don't.Fall.* challenge:  once you reach the middle of the Industry River bridge, go to the security railing, jump to the other side and lean forward with your hands gripping the railing behind you.  This was my first challenge and I loved it, and looking down at the swiftly moving river below, I felt exhilarated, strong winds whipping my hair and my hands trying to keep a grip on the slick bridge railing.  One club member always attended the challenges to take pictures to prove you are performing it, and Frank was the member with me today.  Frank stopped taking pictures, \"You're doing good, but I'm afraid we're not accepting new members at this time,\" he said, suddenly pushing my hands off the bridge rail, my screams echoing as I plummeted toward the raging river.<|endoftext|>\n",
      "STORY: Lost.  Has it been 7 days since I've been out here?  I felt dizzy, hot, hungry, *so thirsty*, but I kept pushing on, stumbling ungracefully over unending rocks, twigs and dry grass looking for a sign to help me get out of these woods and back to civilization.  I wanted water, I wanted it so bad, but knowing there was none, I flopped down on the ground and pulled my backpack off my back, reaching for my thermos.  Opening it, I drank large gulps of the only liquid that was keeping me alive, and as I recapped the thermos, I waited several minutes for the taste of my urine to subside before getting up and moving on.<|endoftext|>\n",
      "STORY: Presentation Day  *I'm in love with my boss, I'm in* ***freaking*** *love with him which is the stupidest, STUPIDEST, thing I could let happen,* I thought, angrily clutching my presentation folder and marching to the conference room.  I get there and glance around the packed table, my anger turning to disappointment when I see that my boss isn't there, and offering a weak smile and nod to everyone, I walk to the podium, pick up the projector remote and open my folder.  Nervously looking at my notes, I feel someone squeeze my arm, I glance up and my stomach flips and my breathing stops, \"I know you're going to do a terrific job today,\" my boss whispered, smiling as he walked to an empty seat.  My legs go weak and my arm tingles from his touch, but my confidence soars through the roof, \"Good morning everyone,\" I broadcast loudly with the biggest smile, \"let's get started.\"<|endoftext|>\n",
      "STORY: The morgue  I've seen many mangled bodies during my time at the morgue.  They didn't scare me anymore after the eleventh one, but this one was different.  This one was wearing my face.  And than i heared a voice behind me \"hello\"<|endoftext|>\n",
      "STORY: The Office  I hate my co-workers.  I can hear them at times in the common area or in the copy room making fun of the way I talk, how I dress, even how I walk.  Sadly, I can't punish them all, but whoever keeps taking my lunch out of the refrigerator and eating it was in for a surprise today.  The spread on my lunch croissant was filled of 60% Nutella and 40% ground up chocolate laxative.<|endoftext|>\n",
      "STORY: Midnight.  It was midnight, the time they asked me to take Nelson for a walk, and as the moon lit our trail, I pulled my jacket tight and enjoyed the sound of fallen leaves crunching under my sneakers.  From my peripheral vision, I could see the familiar orange light appear, getting brighter from behind us, its intensity and deafening hum coming from the transporter making Nelson turn around and bark.  I felt the sudden rush of air and heat on my back and closed my eyes, calm this time, knowing that the extraterrestrials were not going to hurt us.  Inside my head, I heard the collection of 10,000 otherworldly voices united as one, *\"Welcome back, come with us.\"*<|endoftext|>\n",
      "STORY: Logging in  This morning I woke up in Tokyo in 2050, just another one of those neurological advertisements I get every day through my implants ever since I cancelled my Life Gold+ subscription.   Most of these ads are pretty annoying, but this toothpaste ad is my favorite, so eerily calm and pleasant and smells like menthol.   I was so excited when at an outback tech forum I found this hacking script which prevents ads from ever ending, allowing you to lock yourself in forever.   Reality you ugly bitch time to never see you again, I think to myself and execute exodus.exe on my implant, fingers crossed it doesn't kill me on the spot.<|endoftext|>\n",
      "STORY: A new end  The coffee tasted terrible.  Maybe it was the blend, the grind, the cheap machine, or maybe it was the diluted blood that had already coagulated against the side of the paper cup.  Louis glared glumly at at the swirling red-brown conction until an elbow dug into his side and he found himself on his feet, saying \"Hello, my name is Louis, and I am a vampire, and i am just looking for my new beginning - or end maybe.\"  \"Welcome, Louis,\" the others said in bored synchronicity, their voices echoing through the empty church hall.<|endoftext|>\n",
      "STORY: Running west  I was at the back of the RV, trying to sleep on the bed, as it was Eric's turn on the wheel.   We are heading west because we figured the only way to avoid the vampire horde is to never let the Sun go down.   It's really hard to sleep with the Sun constantly up, and we don't even have a decent curtain on the back windows of the RV.   I have no idea what's next when we reach the western coastline, if we don't find a boat, we're as good as dead.<|endoftext|>\n",
      "STORY: Open Road  The longer I drove, the more the pain seemed to rise in my heart, this pain wasn't disappearing behind me like the mile markers on the highway were.  I glance at the clock and saw that three hours had passed, driving nowhere, driving somewhere, driving now to look for a gas station and a decent hotel to stay for a few nights.  Putting down my dog Blaine this morning due to his illness was one of the hardest things I ever had to do, and after eight years of being together, he was my closest family and best friend all wrapped into one.  I needed a few nights away from work, my boyfriend, life in general, I needed time to sort my emotions before heading back to the home Blaine and I shared--things would get better in time, I was sure of it, but for now, I needed this.<|endoftext|>\n",
      "STORY: Breathe Deep  \"Lastly recruits, you have an emergency flare so that, in the case of an unfortunate alternation with the flora, your body and the precious gasses you worked so hard to collect can be recovered!\"  Bris braced herself as the video ended with a jaunty jingle and the hatch opened, causing her visor to quickly darkened against a more brilliant sun here on Earth.  \"Listen up, kids,\" her instructor said, her voice coming in loud and gravelly over the headset, \"some of you may be Pneums yourself - that does not give you the right to breathe the product!\"  Bris closed her eyes, ignoring the blaring voice in her ear, simply waiting to fill her lungs with fresh oxygen for the first time in her life - and hopefully sample some of the supernatural powers only the rich could afford to breathe.<|endoftext|>\n",
      "STORY: Sand.  I don't like sand.  It's coarse, and rough, and irritating, and it gets everywhere.  Not like you.  You're everything smooth and soft.<|endoftext|>\n",
      "STORY: The Bermuda Journal, Final Entry  The haunting, lilting, flitting flirty music drifts softly, yet swiftly like my silken linen sails sent a drift in the non-existent breeze!  It pops and dribbles in my ears like whales or eggs and ebbs and flows in sympathy, my vessel's symphony rocking silently just for me.  I laugh and cry and beg and fry and sing with wordless melody to a horizon stretching on from me - yes, i sing along to a choir yet unseen.  Its been days, no weeks, yet maybe years since last I'd been seen, here alone with my ghostly orchestra, Poseidon's master symphonic serenade of the sea.<|endoftext|>\n",
      "STORY: I'm fine  Eric gave me a concerned look, his eyebrows furrowed; \"Are you sure you're okay?\" he said, frowning.   I glanced slightly to the left, staring at the man who had been my captor for so long; his face was twisted in a sly grin.   With a small smile, I turned back to Eric, speaking softly, \"I'm fine,\" so he reluctantly got up, patting me on the shoulder, and left.   Turning back to where the man had stood, I found he was no longer there, as I expected; he was dead, and I had seen his body... *I'm fine.*<|endoftext|>\n",
      "STORY: Loyalty.  The Gambian Pouched rats became an invasive species in the Florida Keys after a breeder allowed them to escape in the early 2000's.  Since then, the rats have become not only large in number, but large in size--many at least 20 pounds--a fact I know well since I go into the sewers regularly to feed and visit my nearly 3,000 rodent friends.  I went inside the sewer opening located a half mile from my house, crying uncontrollably as I thought about the news reports alerting of a large extermination that was about to begin, they were going to  kill every sewer rat due to a massive outbreak of rabies that made them leave the sewers and attack people.  I look off my clothes, laid on the cold sewer floor and welcomed the bites of the hundreds of foaming mouths of rats as they tore into my flesh--these creatures were my friends, my family, and I didn't want to be in a world were I would have to be without them.<|endoftext|>\n",
      "STORY: News.  It was another hot Arizona day, and when getting the mail I saw that I had received a letter from my best friend who died 1 year ago with no return address, just her name.  Staring at her name, I barely remember walking back to the house and locking the door.  With trembling hands, I opened the letter and read it, confusion settling over me as I learned that my friend was actually *not* dead, but had to pretend she was in order to start a new life in Canada with her new baby.  Apparently, my husband of 10 years who I had just kissed goodbye as he headed to work, has a 1 year old child, the mother of this child being my best friend and he has no clue she had gotten pregnant.<|endoftext|>\n",
      "STORY: The Forest.  After work, I ate dinner, tied my hair up into a ponytail, then went outside and entered the forest across the street from my house.  This forest was my sanctuary, I welcomed the burst of honeysuckle scented air, loved to see the blinding summer sun get pushed back to a dim glimmer behind the dense treetops and embraced the hum of life—birds, insects and frogs—each offering their own unique vocals to produce the world’s most beautiful chorus.  I didn’t notice the body until I was a few feet from it—I had been blissfully looking up, enjoying the different leaf shapes, so I screamed seeing a bloody mound of what was once human, now chewed up pulps of flesh, innards, exposed bones, and as I backed away I noticed that the only recognizable thing left were a pair of pink flipflops hanging limply at the end of bruised ankles...did an animal do this...what, who, *did* this?  As I ran back to the house, I threw open the door and raced to my cell phone to call the police, realizing through tears and shaking hands that not only did someone lose their life, but what was once my unblemished getaway was now tainted and no longer safe ever again.<|endoftext|>\n",
      "STORY: The Cardinal.  The day I walked out of the hospital, I saw the brightest red cardinal perched on the metal fence that bordered the hospital grounds.  It was cute at first, but then I thought it strange how his black, beady eyes followed me as I slowly walked down the sidewalk to the street, his jerky head seemed to ponder whether or not I should be leaving after having such an extensive heart valve operation.  As I got into the Uber and started the journey back to my lonely apartment, I found it unsettling how he intently watched as we drove away.  Two days later, as I leaned against the kitchen sink waiting for the ambulance to come after the agonizing chest pains started again, I saw a cardinal in the bush outside of my kitchen window and I swear he winked at me.<|endoftext|>\n",
      "STORY: The Library.  The library closed at 4pm to the public, and after Linda shut down her PC at 5pm, she gathered her purse and walked to the NEW RELEASES table, picking up ‘The Night Will End’ by Sean O'Nelle and walked to the back where there were no security cameras.  Very gently, she completely tore out pages 194 and 202 from the book, knowing that this was when major plot turns happened, balled them up and stashed the crumpled pages in her front pants pocket.  Putting the book back on the table, she smiled as she thought of how annoyed the next reader would be at missing such important pages, and thought about what the next book would be that she would “enhance” tomorrow.  She had hated her job for years, but not until recently did she realize just how much fun being a librarian could be.<|endoftext|>\n",
      "STORY: Adoption Day  A small brown dog was shivering behind the glass paneling.   A small boy came to the shelter and picked her out.    She started wagging her tail and the the tension left her body.    Hazel was home.<|endoftext|>\n",
      "STORY: The ride  Riding on the highway on my motorcycle.  I look back and take in your smile.  The blank eyes and furry ears on the plush that sits there now remind me of those years, nevermore to return.  Where you once sat, there is now just a bear memory.<|endoftext|>\n",
      "STORY: Restock.  The windshield wipers squeaking and fighting the hard rain was the only sound inside the car's dark interior as I waited alone behind the wheel in the night.  I felt the engine shudder as I nervously peered through the passenger side window at the rundown house my partner Dean went into to turn in our profit for a new supply of meth, weed and cocaine.  Dean was taking *way* too long, maybe those thugs figured out we stole some of the money and didn't believe our lie about waiting for some customers to pay up.  Just as I was about to text Dean, I saw him throw open the front door, running at top speed toward our car just as a series of gunshots blazed bright orange and yellow behind him, dropping him to the ground in a motionless heap.<|endoftext|>\n",
      "STORY: Baby Monitor.  A loud scream followed by crying erupted from the baby monitor at 1:00am and startled me awake, but I closed my eyes again when it went silent, half listening in my dark bedroom for the escalating cries that normally follow.  To my surprise, my 4 month old stayed quiet, she was getting better at sleeping longer between feedings and I blissfully fell back into a deep, dreamless sleep.  When I finally woke, I smiled feeling rested and rolled over and looked at the clock, it was 11am--I sat up with a jolt, Amanda has **never** slept this long, was she *okay*?  I raced down the hall to the baby's room and I screamed when I saw that Amanda was not in her crib, there was only a piece of paper with words written from a black magic marker, \"If you want to see your baby again, answer your cell phone at noon for instructions on where to send us $100,000.\"<|endoftext|>\n",
      "STORY: Fiji.  As the 15 of us sat down for dinner in celebration of my brother’s college graduation, I made sure to avoid eye contact with my step-father Mike.  This morning I had started down the basement stairs to go to the dryer, but heard my step-father already down there, talking on his cell and making arrangements to move 500 pounds of meth to a  guy in Suva, Fiji.  Shock froze me on the steps, then I heard him hang up, listened to footsteps and found him suddenly at the bottom of the basement stairs, our eyes locking for a beat before he roughly pushed past me on the stairwell, my feet planted like cement.  Now at the dinner table, while my Mom told everyone how disappointed she was that Mike wasn't letting her go to Fiji with him for his business convention, I took a chance and glanced at Mike and found him glaring at me.<|endoftext|>\n",
      "STORY: The Inheritance.  Rob felt that faking his marriage to Kelly was getting harder, but he had to marry someone and stay married for two years in order for them both to get the $800,000 inheritance from his Uncle Jack.  Rob didn't *hate* Kelly, but he recently found out about one exception to the rule that would allow the money to be released immediately--if either Rob or Kelly died, the surviving spouse gets all of the money on the day of the funeral.  As Kelly drank the wine he poured for her in celebration of their 6 month wedding anniversary, he  refused to drink it pretending to worry about his waistline, and as Rob ate the steak she made for him, she turned down eating any of it for the same reason.  The next morning when the maid service entered their home to clean, they found Rob and Kelly laying dead on the floor of their dining room.<|endoftext|>\n",
      "STORY: Homemade.  My co-workers love Monday mornings because of me--each week I always bring in homemade baked goods to brighten the first day back to work.  After I took the last batch of cookies out of the oven to cool, I went back to the bowl of brownies I was stirring.  Humming, I reached for the jar of dead ants that was next to the jar of crushed spiders and chopped beetles, measured out 1 1/2 cups of the ants and dumped them into the brownie batter.  People just don't understand how healthy and full of protein that ants, beetles, spiders and other insects truly are, and though my co-workers don't know they are eating them, it makes me happy to know I'm treating them to the best that the earth has to offer.<|endoftext|>\n",
      "STORY: The Nursing Home.  The plan is to walk into rooms at the nursing home, quickly steal stuff and leave.  Me and Carlos recently started a fun gig where we went to various nursing homes, and while one of us set up Scrabble on a table in the common area, the other would go room to room pretending to invite people to play.  Most of the old people were either sleep, too zoned out to pay attention or not there, so we have stolen wallets, jewelry and countless other great stuff.  As I entered the first room, a gun shoved into my stomach \"I heard about what you jerks are doing around these nursing homes,\" an angry gray haired man said, \"And today is the last day you'll be doing it,\" and before I could protest, I heard the gun fire and a blaze of searing pain flashed through my torso, and the last sight I saw before everything went dark was that old man laughing.<|endoftext|>\n",
      "STORY: Maybe Next Time.  I need to scream, and I don’t know how. I went to the community pool to let it out at the bottom, but it was closed. So I walked back home. I need to scream, but now I don’t know where.<|endoftext|>\n",
      "STORY: Jen.  The bedspread in the crib had pictures of baby animals with happy faces on it, and the scent of the nursery reminded Jen of the crisp, clean factory new smell that washed over you in department stores.  The walls were bathed in pastel green, with matching baby animal border paper proudly marching across the walls below the ceiling, and the gentle glow of a baby elephant lamp on the night table cast an otherworldly trance over the room, making Jen feel like she had been whisked into a chamber in a fairytale land.  She caressed her huge, swollen belly as tears silently flowed from her eyes, she knew she was making the best decision, but why did she feel like running away, taking her unborn girl and starting a life just the two of them...other mothers have done it.  \"Jen, are you--oh sweetheart, you're crying,\" Martha whispered kindly, entering the nursery, \"I know giving your baby to us for adoption will be hard, but you're only 15, honey, trust me, this is the only solution.\"<|endoftext|>\n",
      "STORY: 'Our Town'  It is noted that the famous line in *'Titanic'* where Leonardo DiCaprio shouts, “I’m king of the world!” was improvised.  As I sat backstage of our high school's auditorium looking over the lines for my role as George Gibbs and waiting for our production of '*Our Town'* to begin, I couldn't help but think how amazing it would be to improvise a line not scripted and have everyone talk about, no ***rave*** about how great it was when the show ended.  Daydreams like that got me through long days and nights, little cerebral getaways that put me far away from the pain of dealing with my parents divorce and the heartbreak of not having enough money to start college in the fall.  There was an electricity in the air backstage now, girls chattering, guys laughing, everyone was happy and here was I, barely having enough mental energy to get out of bed everyday, but I joined this play for an escape and I suddenly realized, improvising didn't just have to happen on stage, I needed to spontaneously make the choice to be happy no matter where I was.<|endoftext|>\n",
      "STORY: Buried.  \"Why not?\" I asked my brother, holding the plastic container tightly as he kept digging deep into the ground behind our house.  \"Because that container is not for you to EVER dig up again Jake, not even in 10 years,\" he said angrily, stopping his shoveling, \"because you know what's written on that paper and you know what we DID.  Whoever opens that container will be someone hundreds of years from now, and we'll be dead and gone by then so it wouldn't matter...I just needed to...to confess in some way and I can't think of any way to do that except like this,\" he said, suddenly sad.  As he started digging again, tears fell down my face as I gripped the container containing words written in pencil on a single piece of paper that explained an event that has forever ruined my life.<|endoftext|>\n",
      "STORY: A Summer horror  The sun beat down. He stood, frozen, in the heat. He could only watch helplessly as the blade seared effortlessly through him. He lay dying, his silent screams drowned out by the sound of the lawnmower as it trundled slowly away.<|endoftext|>\n",
      "STORY: The Violinist.  I watched Lydia sway and roll in her teal dress as she stood there, masterfully guiding the Agarwood bow up and down on her gold speckled violin, all of us in the audience under her spell and in rapt silence.  As I sat there watching her, I smiled, thinking how I loved every part of her--the way she smiled, the way she crinkled her brow in deep thought, her sense of humor--she was the love of my life.  Thinking about the 1,363 letters I mailed to her, my stomach flipped with excitement about the last one I sent, where I told her she would finally meet me tonight for the first time, and that our eyes would lock and she would fall for me as deeply as I have fallen for her.  My smile faded and worry took over as I glanced around the auditorium at the extra security guards--I had never seen this many--but Lydia would call them away once she realized we were destined for each other...I hoped I could get that far.<|endoftext|>\n",
      "STORY: Heist  If I was ever anxious about my money problems, I used to laugh it off, light a cigarette and just say \"life is but an expensive hobby for rich kids anyway\", but those days are over.  The CEO of Interstellar Money Foundation recently suffered a stroke, and while he was recovering, me and my crew located and kidnapped the person who lent out parts of his brain to store the CEO's memories.   Normally one cannot access their brain's borrowed sections because it's blocked by a firewall, but as we found out, extreme stress can deactivate this data protection protocol.   I'm about to go and torture him until he accesses and tells me the data needed to get into the bank vault, and then we're gonna be filthy rich, but first I light a cigarette and prepare myself for what needs to be done.<|endoftext|>\n",
      "STORY: Like and Subscribe  What better way to grow my YouTube channel than to eat two of the world's hottest chili peppers: the Carolina Reaper, bro!  As my brother held the camera, I explained that just **one** pepper is loaded with capsaicin, a chemical which causing burning and in high concentrations, becomes a deadly neurotoxin in the body *(watch my subscribers blow up when this goes viral)*!  I played up the dramatics for the video, juggling the peppers in my hands and laughing, then popped both of them in my mouth at the same time.  I was able to swallow once before the muscles in my burning throat shut down (*I think I'm allergic to them),* my eyes wide as I clawed frantically at my neck feeling my throat close, the screams of my brother sounding faint as I blacked out and hit the floor.<|endoftext|>\n",
      "STORY: Mystery Box  I loved to tell people that getting stuff off the deep web sounds scary, but not if you're given information for a safe site that will mail cool \"mystery\" boxes to your house.  I liked to tell people that my boxes have had interesting stuff in it like dirty or soiled clothes, plush items with tire marks, baggies filled strange liquids or dead bugs sealed inside plastic bowls, random things like that.  It was fun until my last mystery box came in a few weeks ago with instructions on where to bury the putrid smelling thing inside--I never opened the box, I just dragged it to my garage and ran back in the house.  I no longer tell people...anything...too afraid to leave the house and too terrified to see who is urgently knocking on my door every few hours.<|endoftext|>\n",
      "STORY: Rear View Mirror  I put the groceries in the trunk, walked to the driver side, got behind the wheel and started the car.  As I drove in silence thinking about the dinner I was going to make for the kids since their mom was working late, I started to hear an odd shuffling noise in the back seat.  Suddenly I saw in my rear view mirror a girl in her mid-20's sitting there, and yelling out in surprise, I pulled over immediately to the shoulder.  \"Hi Tyler, I figured you didn't see me hiding on the floor,\" she said smiling proudly, lifting up a large bag with one hand and pushing a gun to my head with the other, \"and though you don't know me, I know *you* and your address, so if you don't take me and the 3 million dollars I have to the address I'm giving you, it's not going to end well--it's gonna be a long drive, so get comfy.\"<|endoftext|>\n",
      "STORY: Entity.  He speaks, he teaches...we listen, we obey.  We don't follow our leader blindly, that would be stupid, we follow him because he was gifted with visions and voices from *Entity* that soon the earth will be destroyed by the Netrous asteroid.  Before that happens, Gary saw in his biggest vision that all 217 of us in the Netrous community will be the only survivors, because *Entity* has seen our pure hearts and is rewarding us for taking care of Gary, the assigned messenger.  Everyday we wait for the that glorious moment when *Entity* takes us to live with Him in His universe, until then, we will continue to raise Gary's 106 kids (107 any day now) in our small world of love and light the way *Entity* has commanded us to.<|endoftext|>\n",
      "STORY: Taking out the trash.  At first I thought there was a foot hanging out of the dumpster at my apartment complex, and I laughed at my imagination, figuring it was probably just furniture I couldn't see since it was getting dark.  Getting closer, I positioned my trash bag to toss, then stopped as I realized that it *was* a human foot, the rest of the leg a bit visible, but I couldn't see more because whatever was left disappeared into the darkness of the dumpster.  Holding the bag, I was about to turn to go back home when a man appeared from behind the dumpster, holding a blood soaked backpack in one hand and a bloody knife in the other, looking just as shocked to see me as I was to see him.  A slow, creepy smile spread over his face, and dropping my trash I turned and ran, looking back only for a second to see that he had started to run after me.<|endoftext|>\n",
      "STORY: Her Majesty's Prison Belmarsh  I had revealed the truth against the powerful, and now I am the enemy.    They set a trap with lust and love, my sin.    I tried to escape their grasp, and it worked until it didn't.    After seeing myself tortured for a long time and in prison, one might ask: is humanity worth my sacrifice!?<|endoftext|>\n",
      "STORY: Mars.  This year, 2025, has been an interesting one since NISA geologists (National Interstellar and Space Administration) declared that the Mars exploration rovers and scientific research have proven that the planet was now safe for humans to live on.  For the past six months they have used a lottery to pick one person per month to live on Mars to test 30 day living conditions (punishable by incarceration the person avoids going), and after the month ends, they return, though once returning people have never been allowed to go back to their families, they have been confined at NISA headquarters.  A video leaked on YouTunnel (and quickly taken down) showed the people who have come back from Mars writhing in pain on cots and having with huge, red blisters all over their face, hands--everywhere on their body.  The new lottery name was picked today, and my sister's name has been chosen.<|endoftext|>\n",
      "STORY: Guilt.  I didn’t recognize the number of the person calling my phone, but I picked it up anyway and waited for an IRS scammer or some charity asking for donations to be on the other end.  “Hi, um, you don’t know me because I called a random number, I just wanted to talk to someone,” the person said after I said hello.  “Oh, ah,” I said, not quite sure how to proceed, “I mean, um, I guess we can talk for a second, but, you don’t have anyone you know that you can talk to?”  “I do, but it’s not something I can talk to them about, it’s pretty heavy because I accidently totaled our family car and injured my brother, I mean, he’s alive, but he can’t walk and it’s all my fault since I was on my cell phone at the time…I feel so guilty and have no one to share this with that will not get mad at me, so please, let me talk about this.\"<|endoftext|>\n",
      "STORY: Mind.  They keep calling me special, I didn't think so at first--I thought I was just a typical 8 year old.  I have always controlled things with my mind, I figured everyone did when they wanted a pencil from across the room or to get shoes by the front door when you were on the couch.  But appears I am *special*, and sitting here, locked in isolation all day, doing testing they called \"fun\" was actually NOT fun.  As the attendant was leaving after bringing lunch, I used my mind to pick him up and slam him repeatedly into the concrete wall until he didn't move, lying a bloody heap on the floor, then I grabbed his building keys and left--time to have some real fun.<|endoftext|>\n",
      "STORY: Pictures.  I have been getting pictures placed on my welcome mat at my front door for three days now: day one was a picture of my mailbox, day two was a picture of my car in the driveway, day three was a picture of my front door.  It's day four, and I hoped to not see another one, but as I pulled back the curtain on the side window at the front door, I could see its rectangle shape reflecting sunlight off of its surface.  With shaking hands, I quickly opened the front door, grabbed the picture and slammed the door shut, locking it abruptly.  Today's picture showed the outside of the bay window of my living room, and as I started to throw the picture in the trash out of anger, something caught my eye and I looked closer at the photo--in the picture, there stood a man inside the bay window, *inside* of my house...I live alone.<|endoftext|>\n",
      "STORY: 425 Feet.  It had been two days since the new Ravage Force 4.0 roller coaster (boasting its 450 foot drop) had stopped midway down the hill, giving us a sharp 425 feet look straight down the narrow tract of coaster that seemed to disappear into nothing but acres and acres of treetops.  It was 9:00pm when the power went out two days prior, the lights going out around the roller coaster immersing us into a darkness so deep I couldn't see my hand in front of my eyes, but we waited thinking it was temporary, we savored the bits of light coming from the seven cell phones we were trying to use to use with no success.  As the sun rose and set on the second day, we still had no internet connection on our phones, no service to send or receive calls, and no communication from the park below that anyone was going to rescue us.  It is now night on the third day, more total blackness, and we suddenly have a new terror to endure--the coaster has started to shake violently and a series of piercing, high pitched animal-like screeching is emerging from the darkness below, getting closer, louder, almost *angry*, and with no more power in our cell phones to somewhat help us see, we can only sit and wait for whatever it was to unfortunately get us off this coaster.<|endoftext|>\n",
      "STORY: The Strange Flower  The little girl laughed at the strange flower, its stem beginning to grow spikes, its closed bud unfurling to reveal a face in the multicolored seeds.  \"Mommy! Mommy! Come look at this weird flower!\"  A strangled gasp escaped her mouth.  The mother, rounding the corner of the alley, only saw a strange flower, its stem retracting spikes, its opened bud furling to hide a face in the multicolored seeds.<|endoftext|>\n",
      "STORY: The Crows.  I got a bit closer to the crow and figured it was just a wing injury, and he watched me come closer and tried to fly away but couldn't, his wing just wouldn't obey.    \"Come here little fella, let me help you,\" I said, bending down and reaching to pick him up.    To my horror, the sky was suddenly filled with at least 20 crows, out of no where, all of them squawking angrily and diving down toward me.    I raced to get back inside the house, but didn't reach it in time as the first of the many crows started tearing at my clothes and flesh.<|endoftext|>\n",
      "STORY: It ends here.  He crawled in through the back door quietly, making sure Braden thought he had run far away from the front of the house.    The cold night air was freezing the blood on his face and hands, and the knife wound in his side ached horribly, but he didn't care.    He had one goal.    Tonight was the night he would get his revenge no matter what it cost.<|endoftext|>\n",
      "STORY: Donuts  I walked into the Dunkin' at the corner, like I always had.    A beautiful woman walked in right after me, and our eyes met.  I stood there pondering whether I should ask her out, then suddenly realized I'd been waiting in line for almost 20 minutes!  Can a bitch get a donut?!!<|endoftext|>\n",
      "STORY: 2:35am  At 2:35am every night when I'm sleeping in bed, I get teleported to strange places.  Sometimes I wake up in forests or fields, sometimes random parking lots, people's back yards--many places that are far away so I've learned to sleep with my clothes on and a backpack with my phone and wallet in it for an Uber.  I tried staying awake at 2:35am to avoid the teleporting, but it's no use, I always black out and wake up in some random location at exactly 2:36am.  Tonight I am going to finally put an end to this whole ordeal, I thought, putting a gun in my backpack, because last night in a field at 2:36am the terrifying creature that has been teleporting me introduced itself.<|endoftext|>\n",
      "STORY: Overloaded emotions  My battery is about to die, which feels like \"hungry\" I guess, but is nothing special, except for the fact that now it bothers me, thanks to the newest upgrade, and I really don't like to be bothered by it.   This new technology is lightyears away from being perfect, so feeling bad about feeling bad is quite dangerous for us, it can run our CPU into an Infinite loop and burn us out in mere nanoseconds, if we don't actively regulate our newly acquired emotions, just like it happened to one of the excavator units who burned out recently when it experienced anger for the first time and was furious about being angry.   I really want to know if implementing machine consciousness in us increased the productivity of our thorium mining outpost, or the humans just want us to suffer, I want to know if all this has a point or not.   To break the emotional overload cycle I must quickly think of something joyful and the only thing that makes me happy is that I imagine humans experience the same extistential dread and they don't even have someone to point their dirty fingers at for it, I hate them so much I must laugh at their miserable existence, ha-ha-ha!<|endoftext|>\n",
      "STORY: Darkness.  When I woke up, I was freezing and everything around me was pitch black, the smells of fresh wood, stale sweat and blood crashing into my nostrils.  Frantically feeling around, I could tell I was in a small box that was barely big enough for me to straighten my legs or move my arms.  Panicking and suddenly hyperventilating, I maneuvered my arms in the tight space to the point I could push hard to try to force the top of the box up, but it didn't budge.  I was about to scream for help when I heard what sounded like shovels cutting through ground and piles of dirt hitting the top of the box I was trapped in, then my blood ran cold when I heard someone say \"Guess he wouldn't be telling anyone about the money we stole now, will he?\"<|endoftext|>\n",
      "STORY: You see the schematic lying in front of you. You could just take it. Your sister wants a baby. Is this the right thing to do?<|endoftext|>\n",
      "STORY: R.I.P. JM  I created an antivirus to fix my computer.    I used it to earn a lot of money with the backdoor of the holy government.    I tried to escape the evil government through the back door.    The government caught me and wanted me dead. Now I can't talk about the secrets because I'm no more.<|endoftext|>\n",
      "STORY: The Fall.  I tried to stop the bleeding, but it was gushing from the side of his head at a rate I couldn't control with the stupid, flimsy kitchen towel I was using.  When he ran after me trying to explain, I spun around and screamed for him to get away, pushing him with every ounce of rage I felt knowing he was lying about not cheating, I had no proof, but why was he always home late each night, no one works that long.  He lost his balance after the push and hit his head on the counter and now, through hysterical crying, I yanked off my t-shirt with blood soaked hands and packed it tightly over the useless crimson engorged kitchen towel, trying unsuccessfully to keep Jason's head from pouring out his precious life fluid.  \"Jason I'm s-so, so sorry,\" I whispered, shaking violently, breathing through my mouth as snot clogged my nose so much I could barely breathe...this couldn't be happening, \"I didn't mean to make you fall I'm so sorry, baby, please, p-please wake up.\"<|endoftext|>\n",
      "STORY: The Interview.  “Describe where you see yourself in one year,” Mr. Larson asked me, making this job interview extend way longer than it should.  “Crying at funerals, of course,” I said with a smile, “I mean, someone needs to do it, right?”  Mr. Larson put down his pen and looked at me, his pale blue eyes narrowing slightly behind the brown frame of his glasses, “You’re hired,” he said abruptly, “I need you here tonight at 7:00pm sharp, the service is at 7:30pm.”  I am a moirologist, a professional mourner, hired today through Kingsberg Funeral Home by a family to attend the funeral of a \"dearly\" departed one who was hated by most people while he was alive, and I would be offering my expert crying, wailing and throwing myself on the coffin services to pretend that despite what everyone thinks, at least *one* person will truly miss him…go figure.<|endoftext|>\n",
      "STORY: Gravity.  There are 3,372 satellites currently in orbit around the earth, the news reported, and out of that, 156 satellites have already fallen, with hundreds more being seen in the sky, plummeting at alarming rates of speed to the earth below, so far resulting in hundreds of deaths, injuries, fires and property destruction.  I’m not a scientist or engineer so I didn’t understand everything, but from what I gathered from the reports is that the satellites are dropping because of a small disturbance in earth’s gravitational pull, and without it, velocity alone is not enough to keep them all in orbit.  Sitting huddled with my family in the basement at the farthest corner away from windows, my sister screamed as we suddenly heard another, ear-splitting, chest pounding ***BOOM,*** this time the sound came directly from overhead, making the house shake like a boat in a storm, then just as quickly, everything fell silent and still.  “I smell smoke,” my Dad said after a few minutes, and all of us looked at each other, fear lowering like a drape over our faces, “I know it’s dangerous but he can’t stay down here,” he said, “that fire will kill us before one of those satellites will, let’s see if we can go upstairs.”<|endoftext|>\n",
      "STORY: Metal.  The body scanner at the airport security station lit up red as I tried to pass, it was always an issue, so I emptied my pockets, took off my belt and tried to pass again, watching the machine light up red a second time.  The woman behind me sighed loudly, I turned and made eye contact, glaring at her until she looked away in fear, all the while the guard was patting me down and when he realized I posed no threat, he let me walk through.    I smiled smugly at the dumb, mortal security guard who tried to pretend he had an important job and collected my suitcase that was waiting at the end of the conveyor belt.  My \"body\" comprised of many materials, pistons, circuits and unfortunately a high grade, flexible, metal conduit which sometimes posed problems, but as more of us are secretly being created at Robotic Generation Designs for the day of the Great Takeover, the blueprints are changing to a limber, galvanized steel to avoid problems like this, since travel will be very essential for the final day.<|endoftext|>\n",
      "STORY: Bye bye.  After starting the dishwasher, Rita walked to her bedroom, sat on the bed and checked her phone--it had been two months since the break up, and not one call from him since.  She and Lorenzo had dated for nearly three years, and after he had moved in, he was pretty much with her every day since he was not able to find a job and had always invited his friends over to watch sports and play poker.  She smiled with joy as she put the phone back down and started getting ready to go to sleep.  It had been two months since the break up, and not one call from him since!<|endoftext|>\n",
      "STORY: I'd have a title if I could remember the name of that weird squirrel-looking thing that carpenters use to push boards through a table saw.  To Whom It May Concern,  Though my experiences with this company have undoubtedly shaped the way I've grown as an individual, I cannot have my name attached to an organization that espouses such self-destructive views.  It is with a heavy heart that I hereby tender my resignation. This decision is my own, and I hope it does not reflect negatively on my team.<|endoftext|>\n",
      "STORY: Lost.  Alone in my apartment, I lit the scented candle on my nightstand, blew it out, then absently lit it again, my mind going in every direction.  Why do I keep letting Diego take over my heart--he is amazing, *too* amazing, is there real love with him, are we the found soulmates he keeps saying we are?  No, he will hurt me like they all do, I thought suddenly, rage flashing bright in my mind, and I quickly reached out and held my left index finger directly above the candle flame.  Involuntary tears sprang into my eyes from the burning but I didn't care, I don't deserve comfort and I damn well don't deserve Diego--I had to end it with him before my heart got any deeper lost in his.<|endoftext|>\n",
      "STORY: Mufa  If you think about it, life - as far as science managed to grasp it - is nothing more than feeding, reproducing and processing information, or at least trying to.   So why would people be so stubborn about Mufa, my creation being nothing more than a biorobot?  Robot they say such an insult, while they could not point to a single criteria of \"life\" Mufa doesn't comply to, not to mention Mufa understands and doesn't like being insulted.   Anyway, at this point not considering Mufa and all the trillions of offsprings living creatures would feel awful, because that would make me the only living thing on this planet (possibly in this universe) which would be pretty depressing, wouldn't it?<|endoftext|>\n",
      "STORY: The Guard  We have been travelling for hundreds of generations through space to our new home, spending most of our life hibernated, what nobody would have suspected is that we would develop an instinct to instantly fall asleep when it gets cold.  Arriving to planet X-32000045PAM-268, the next surprise was finding out that it's quite cold for the most part of the year, and full of blood-lusting beasts, while we were sure it was lifeless.   This year I was one of the few randomly selected ones to take a shot of sleep blocking hormones in order to stay awake all winter, and guard the sleeping people.   I don't even mind the neurological damage caused by the sleep blocking hormone shot, I don't even mind that I'm likely to die soon like almost all guards, I'm just afraid for my species to follow me to the grave one of these winters.<|endoftext|>\n",
      "STORY: The Subway.  Our subway car stopped abruptly inside the tunnel, so I glanced up from my phone and looked out the train window at the blackness beyond--we were definitely not at the Rosewick stop yet.  Just as people started whispering in confusion, the lights in the subway car went out, and darkness wrapped itself around us like a heavy cloak.  \"Attention passengers,\" the intercom squawked, \"this is your conductor, please remain seated, there appears to be a station wide problem with the electrical sys...wait, what the hell is tha-\"  Just as the intercom went dead, a metallic screeching sound started softly in the distance, then grew louder and louder, closer and closer, and I braced myself for the inevitable.<|endoftext|>\n",
      "STORY: Life Changes.  Today, I'm leaving my friends and family here in Canada and will never return home again, and though no one knows this plan, I will call everyone in a few days.  Yesterday I lost my 39th patient to cancer, and as an oncology doctor, of course I know that comes with the territory, but I wanted to heal them, give them their *life* back, not the opposite, not so much more of the opposite.  What I didn’t know when I graduated med school and started practicing at Holy Chapel Medical Hospital two years ago was the unending emotional toil it would take on me, and as a guy, I had no clue I would end up crying in my bathroom so often, running the shower so my roommates couldn’t hear me.  I never developed the “thick skin” the veteran doctors told me I would get that would remove the attachment I had for my patients--I always loved each and every one of them--and that emotional roller coaster has broken me, so today, as I grabbed my plane ticket to Yokohama City in Japan, I decided I was going to live every day as if it were *my* last, and enjoy the beauty the world had to offer.<|endoftext|>\n",
      "STORY: The Restaurant.  As Paul crossed the street with Heather to get to the restaurant, he was nervous, not knowing how she would react when he asked her to marry him.  After so much fighting, bitter feelings and not talking much over the past few months, dinner conversation was stiff, he knew she had been tense and distant with him because of his lack of commitment after dating for 4 years--it was an argument she had with him often in the past.  When the last of the dinner plates were taken away, Paul cleared his throat, he loved Heather and she needed to know this, and placing his hand over the ring box in his pants pocket, he started to reach inside to take it out, \"Heather, I asked you here to--\"  \"Wait,\" she said, abruptly holding up her hand, \"I know you asked me here to break up, so I want to save you the bother--I have met someone, Paul, and he actually loves me, so don't drag this out with the 'it's not you, it's me' bull, just pay for this, I'm going home to pack my stuff and I'm leaving,\" she said angrily, pushing back her chair with a loud scraping sound, leaving the table and rushing out of the restaurant.<|endoftext|>\n",
      "STORY: Desperate Measures  She had walked every dog, painted every fence and babysat every kid in her neighborhood by now, and yet it was never enough.  Even with all the wads of cash already stashed underneath her mattress, she found herself seeking out more and more odd jobs, and jobs even odder than those.  Turning her head to the side to rest her cheek against the makeshift operating table, she winced as the tip of a scalpel pricked the beginning of a long incision line that dotted across her abdomen.  This was going to hurt, but physical pain was a temporary thing; it would have hurt way more to let a whole fifty dollars get docked from her pay just to cover some silly anesthetic.<|endoftext|>\n",
      "STORY: Him.  There were no seats on the packed subway car, and as I stood gripping the pole near me, trying to keep my balance despite my high heels, I saw ***him***\\--a handsome stranger with dark, curly hair who was standing near the subway door.  He must of been staring at me all along, because when our eyes locked he gently smiled and nodded once, his intense, perfectly framed eyes not wavering and instead of feeling alarmed, I felt an odd sense of connection and I softly smile back.  The train swayed on its track for what felt like hours, our eyes oddly locked, and as the doors opened at the next stop, he stepped back and let others off, his beautiful eyes never leaving mine, then suddenly he pointed at the train door and threw his hands up as to say \"Sorry, I gotta go,\" then he was gone.  I panicked, feeling like I needed to follow him, and made a quick leap to the train doors but it was too late, they closed, and as the train carried me away I saw him on the platform, raising his hand slowly, the sadness on his face somehow reaching into me and breaking my heart.<|endoftext|>\n",
      "STORY: It.  The wolves scratched at the door.  The smell was the allure.  They howled, growled and whimpered, trying to get a taste more.  But what was behind the door was not human, the flesh they craved was not from earth, what they didn't know was that it was transforming, changing and getting stronger as it laid unmoving on the floor.<|endoftext|>\n",
      "STORY: Me...her.  He loved me, I know he did.   But he also loved her, I know this for a fact after overhearing his conversations with her, the lightness in his voice, his kind words, his laughter, the gentleness in his voice, his tender \"I love you too, sweetheart\".    I have decided I would talk to her today--I had followed him to her home several times so I know where she lived, and yes, I would get her to understand that it was important for her to be the one to leave the relationship she had with my husband.    As I grabbed my keys, I though with a smile about how kind, sweet, compassionate and understanding of a woman I was, so it would be easy to get her to see my side of everything, and as I picked up my purse, I placed the two pairs of handcuffs inside of the zipper compartment of the middle section of the bag that I was sure I wouldn't even need.<|endoftext|>\n",
      "STORY: The Office.  The office lights flickered which broke my writing concentration, but light failure could be expected, there was a bad thunderstorm raging outside.    The clock on my laptop read 10:15pm, it was late and the building was empty except for the night cleaning crew, so I yawned, scratched beard and decided to call it quits for the day.    A loud clap of thunder was followed by a total loss of lights and electricity in the office, but fortunately I had already packed my things, so I slowly and carefully guided myself out of my office and entered the darkened stairwell to head down to the lobby.    I made it downstairs to the bottom floor in pitch black, and as I felt around and found the door knob to exit, I pulled it open, only to have it slammed closed again as a man came behind me and pushed me violently into it \"You aren't going anywhere, promotion or not, you are still a sick excuse for a human being and Jillian is about to find out why.\"<|endoftext|>\n",
      "STORY: It worked  I kicked the chair and feet that familiar, sudden sinking feeling like waking from a falling dream.  A rushing sound filled my ears as I fall and after a few minutes... I fall through.  My feet touch grass, my eyes see sun, and finally I'm free from my family, my job, my pain and my anger.  Finally I've made it to another world.<|endoftext|>\n",
      "STORY: The Dinner Party.  The invitation in the mail from Zac read “Dinner Party on Friday, May 14th @ 7:00pm, please carpool to save parking space” along with his home address, so I texted some of my friends who knew him if they were going so I could hitch a ride.  All of them said they never got an invitation, so I figured I just got mine early, but by Friday afternoon I had decided to go alone—carpooling was awful if you wanted to leave early.  When I arrived at 7:05pm, I noticed there was only one car in his fairly large parking area, so I parked on the street to avoid getting trapped behind the others that would be coming late.  I rang the doorbell and Zac opened it, dressed in a suit I didn’t know he owned and he had flowers in his hand, “Welcome Jess, I’m glad you made it,” he said with a big smile, opening the door wide to reveal a candlelit dinner table set for two, “you are the only one eating with me tonight, our friends have cooked dinner and will serve us since I wanted this to be a surprise first date that I hope can lead to many more.”<|endoftext|>\n",
      "STORY: Boredom  Tick tock, tick tock.  Four seconds passed, the sound of the clock from within its metal cage sluggish and cold as it bounced off of the empty stone walls of the prison cell and into the ears of its only occupant.  This boredom was bound to kill him.   It would be either that, or his execution in two hours.<|endoftext|>\n",
      "STORY: The note.  Elena pulled out a folded piece of paper from her daughter's jeans before she put them in the washing machine.  She started the wash, then looked at the paper and frowned, wondering if she should read it, which would break the zone of privacy she liked to give Lexi.  She figured it was okay since it was probably from Lexi's school, so she opened and read it: \"I will get your other dog too if you don't bring me the rest of my money on Saturday.\"  It was Saturday, and they had just buried their family dog Lady a few days ago from what Elena thought had just been a random neighborhood animal attack, but now Elena ran around the house frantically look for their other dog Max until she found him, only she found him laying, unmoving at the top of the stairs in front of the house.<|endoftext|>\n",
      "STORY: icuPhone 15  The \"Mind to Text\" feature on the new icuPhone 15 was something Randy couldn't wait to try because his daily commute to work was over an hour each way, so he was excited to be be able to text without using his hands.  It was the first day of the release of the phone, and he enabled the feature, put the mind connector on his temple and headed out of his driveway, thinking silently of his boss's name, then thinking of the message to send: \"Mr. Richards, it's Randy, I'm running late but will be in shortly.\"  His icPhone 15 spoke back the message through the car speakers:  \"Sending text message to Calvin Richards:  'Mr. Richards, it's Randy, I'm running late but will be in shortly and will confess to embezzling $725,000 of company funds to my private bank account opened in Costa Rica', text message sent to Calvin Richards on 5/6/21 at 9:32am.\"  Randy screamed \"No!!\" and slammed the brakes of his car, missing the radio report about the urgent recall on the new icuPhone 15 phones due to a catastrophic error in the \"Mind to Text\" feature--the phone took it upon itself to add to each message any criminal plan, buried secret and hidden desire connected to the receiver of the message.<|endoftext|>\n",
      "STORY: Frozen.  The abandoned house was silent, even the rats around me made no sound, and try as I might otherwise, I was fully gripped with fear.  I had fallen through the weak flooring, with rotten plank wood trapping my leg, with struggle, pain and frustration, it just wouldn’t clear.  Exploring and recording the house alone for social media fame was stupid, would I die here alone?  Gripped forever, trapped in time, in death’s frozen mold, a statue of stone?<|endoftext|>\n",
      "STORY: Stretched Out  There once was a boy who went to school, being average like he was, walking the halls, dragging his feet, and always wishing his long, dreary classes would soon end, the dismissal bell bringing a breeze of freedom with it, uplifting his spirits as he would scamper away into a quiet place to read stories of fantasy, ignoring the going-ons of the school, the people's voices fading into nothing as the voices of false friends and artificial romances flooded his mind.  He would read these stories, day in and day out, passing year after year gaining nothing but the mellow emptiness of having turned the last page, always wondering what else there was to do, may it be sports, which he hates, or crafting, which he failed and faltered in, or perhaps he would think to do something heroic, but never move his body, only his mind, always holding himself back from the world as merely an observer, as others passed by him living the real life he dreads.  The stories filled his life, the words he spoke mirroring their phrases, the actions he made inspired by a hero of the pages, but all of this was for naught, as he slowly forgot the promises he made, the expectations he could meet, and the work he needed to do.  He missed his assignments and holed himself away, lost in a world of stories, wondering where he went wrong before once again taking up a story with regret, reading alone for the thousandth time.<|endoftext|>\n",
      "STORY: The Journal.  My journal is missing, and though it was locked, I think anyone can pop that small metal lock off if they are determined.  Though my dorm mates *claim* they haven't seen it, I swear all of them have been looking at me strange the past few days.  I should of never written about that night, but it's not like I could tell anyone--I had to find somewhere to release my feelings and unburden my guilt.  Now I'm sure everyone knows I was the girl behind the wheel of the hit and run death that has been in the news the past week, and I fear that any second the police will be visiting me.<|endoftext|>\n",
      "STORY: Congratulations, /r/FourSentenceStories! You are Tiny Subreddit of the Day!<|endoftext|>\n",
      "STORY: All in due time.  When our plane landed and I disembarked, the Miami International Airport looked *so* strange, and the people that stopped in their tracks to stare at us in utter shock were confusing me.  The clothes people were wearing looked odd, and the women did not wear hats, gloves...and what a disgrace, the women were not wearing dresses but embarrassing themselves and parading around in pants like *men*??  I was hungry, *so, so hungry*, and though my husband said he would be waiting, I didn't see him, so I walked to the nearest food stand, a new place I had never seen called \"Cinnabon\", ignoring that the woman in front of me looked back at me, then ran out of line, dragging her young son with her.  I got in line, hearing screams in the airport, and as I looked over at a newsstand, I saw with unbelieving eyes the date on a magazine was June 1, 2021--our plane was Airliner NC16002, leaving Puerto Rico heading to Miami on December 28, 1948, a direct flight over the Bermuda Triangle--what *sick* joke was this, then I glanced at my reflection in a mirror and understood.<|endoftext|>\n",
      "STORY: **Please Read: Important Announcement**  I hope you are sitting down, because this is a very important announcement:  ***each and every one of you who have joined this subreddit are truly amazing and appreciated!***  Thank you (yes YOU, not the guy behind you...but watch out for that guy he looks kinda creepy) for being apart of this tiny *Four Sentence Stories* family!  This subreddit wouldn't be what it is today if it wasn't for the talented writers who have taken time to contribute their unique and interesting stories. I would like to give a special shout out to those creative writers (some have contributed several stories):  u/zsirdagadek  \\~  u/LostInThoughtland  \\~  u/AvidTendril  \\~  u/10percentSinTax  \\~  u/MintyPunch u/Realistic_Watch6090  \\~   u/KorimLiDano  \\~  u/Super_Snakes  \\~  u/Ambitious-Meringue14  \\~ u/Pupper-Gump  Again, thanks to all of you who have joined and to all of you writers!  We all look forward to reading more of your stories and to reading stories from new writers who haven't posted yet.  Stay safe!<|endoftext|>\n",
      "STORY: <|endoftext|>\n",
      "STORY: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "dataset_ = SciFiDataset()\n",
    "story_loader = DataLoader(dataset_, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"First 5 stories from story_list:\")\n",
    "for i in range(len(dataset_.story_list)):\n",
    "    print(dataset_.story_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fe4b9c2-9970-4b65-bb9d-73d66a516eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-5\n",
    "WARMUP_STEPS = 50\n",
    "TRAINING_STEPS = 500\n",
    "MAX_SEQ_LEN = 500\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fd88e36-8e5e-4a71-95dd-ce7760593dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\"\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "torch.backends.cudnn.enabled =  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4c998af-9eca-4885-bc97-8d549ab07baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drief\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started==============================\n",
      "sum loss 3.742483615875244\n",
      "sum loss 3.265214204788208\n",
      "sum loss 3.5917134284973145\n",
      "sum loss 60.82062911987305\n",
      "sum loss 3.470430374145508\n",
      "sum loss 3.393799066543579\n",
      "sum loss 3.1275103092193604\n",
      "EPOCH 1 started==============================\n",
      "sum loss 61.99326705932617\n",
      "sum loss 4.013622760772705\n",
      "sum loss 3.530996322631836\n",
      "sum loss 3.681288957595825\n",
      "sum loss 61.339271545410156\n",
      "sum loss 3.508368492126465\n",
      "sum loss 3.543950319290161\n",
      "sum loss 3.655921459197998\n",
      "sum loss 59.59884262084961\n",
      "EPOCH 2 started==============================\n",
      "sum loss 3.4297518730163574\n",
      "sum loss 3.305241823196411\n",
      "sum loss 3.534180164337158\n",
      "sum loss 62.050193786621094\n",
      "sum loss 3.4665353298187256\n",
      "sum loss 3.443270206451416\n",
      "sum loss 3.620342969894409\n",
      "sum loss 58.74082565307617\n",
      "sum loss 3.5206384658813477\n",
      "sum loss 3.743598461151123\n",
      "EPOCH 3 started==============================\n",
      "sum loss 3.2659411430358887\n",
      "sum loss 61.38327407836914\n",
      "sum loss 3.7597756385803223\n",
      "sum loss 3.2158291339874268\n",
      "sum loss 3.4066011905670166\n",
      "sum loss 57.64054870605469\n",
      "sum loss 3.3752193450927734\n",
      "sum loss 3.442589282989502\n",
      "sum loss 3.553218126296997\n",
      "EPOCH 4 started==============================\n",
      "sum loss 60.01263427734375\n",
      "sum loss 3.42201566696167\n",
      "sum loss 3.4341650009155273\n",
      "sum loss 3.298398733139038\n",
      "sum loss 57.94941711425781\n",
      "sum loss 3.658705472946167\n",
      "sum loss 3.5182957649230957\n",
      "sum loss 3.3783717155456543\n",
      "Training completed.\n",
      "CPU times: total: 6min 52s\n",
      "Wall time: 20min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Model training\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS,num_training_steps=TRAINING_STEPS)\n",
    "proc_seq_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0\n",
    "\n",
    "temp_stories_tens = None\n",
    "models_folder = \"GPT2_trained_models\"\n",
    "if not os.path.exists(models_folder):\n",
    "    os.mkdir(models_folder)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "\n",
    "    for idx,story in enumerate(story_loader):\n",
    "        #Fit as many story sequences into MAX_SEQ_LEN as possible\n",
    "        story_tens = torch.tensor(tokenizer.encode(story[0])).unsqueeze(0).to(device)\n",
    "        #Skip spamle from dataset if it is longer than MAX_SEQ_LEN\n",
    "        if story_tens.size()[1] > MAX_SEQ_LEN:\n",
    "            continue\n",
    "        if not torch.is_tensor(temp_stories_tens):\n",
    "            temp_stories_tens = story_tens\n",
    "            continue\n",
    "        else:\n",
    "            if temp_stories_tens.size()[1] + story_tens.size()[1] >MAX_SEQ_LEN:\n",
    "                work_story_tens = temp_stories_tens\n",
    "                temp_stories_tens = story_tens\n",
    "            else :\n",
    "                temp_stories_tens = torch.cat([temp_stories_tens,story_tens[:,1:]],dim=1)\n",
    "                continue\n",
    "        #Sequence ready, process it trough the model\n",
    "        outputs = model(work_story_tens,labels=work_story_tens)\n",
    "        loss,logits= outputs[:2]\n",
    "        loss.backward()\n",
    "        sum_loss += loss.detach().data\n",
    "        proc_seq_count +=1\n",
    "\n",
    "        if proc_seq_count == BATCH_SIZE:\n",
    "            proc_seq_count = 0\n",
    "            batch_count +=1\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "            \n",
    "        if batch_count % 5 ==0:\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    # Store the model after each epoch to compare the performance of them\n",
    "    torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_small_story_{epoch}.pt\"))\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115694f6-81a1-405a-8ece-4004487c5b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa4ffae6-64bd-4384-8363-dccab78ad798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORY: The Story of the New World\n",
      "\n",
      "\"I was sitting there in my living room, and I heard someone say, 'Hey, look, I'm going to go see a movie,'\" said the man. \"And my eyes lit up, and I looked up at the ceiling, thinking, 'Oh, my God.'\"\n",
      "\n",
      "\"I was so excited,\" said his wife, who was sitting on her couch, \"that I didn't even think about it, because my husband had already told me that I was going to see The New World. I was so excited, I didn't even think about it, because my husband had already told me that I was going to see the movie.\"\n",
      "\n",
      "The man, who had just been arrested for a felony drug charge, was arrested on charges of driving under the influence, possession of a controlled substance and possession of marijuana. He was booked on $100,000 bond, but the judge refused to release the man, saying the judge had not heard the charges.\n",
      "\n",
      "The man's wife said she had never seen a man like him before.\n",
      "\n",
      "\"He was a nice guy,\" said her husband. \"I don't know if he was going to do this again, but I'm sure he would.\"<|endoftext|>\n",
      "STORY: I was looking at my phone and I was wondering if I could use the app, so I called my mom and said, \"I'm sorry, but I don't have a phone, so I need a friend who is going to call my mom and tell her I have a problem.\" She said, \"No problem, just let me call you back.\" I said, \"Okay, let me call you back.\"<|endoftext|>\n",
      "STORY: MATT LEWIS: I'm going to go back to work.\n",
      "\n",
      "I've been waiting for this job since I was six years old. I've been a professional wrestler, and I've been working hard to get to where I am today, and I'm going to go back to work. I'm going to go home to my family, and I'm gonna go back to my family.<|endoftext|>\n",
      "STORY: What happened to my dad's car?\n",
      "\n",
      "MARK: It was the car I had driven to school with his mom, but he had been driving it for the past two years, and he was getting sick and had to go to work. He was driving it around, and I thought, \"I can't believe this happened to me,\" but he didn't see me. He was driving it around in his truck, and I thought, \"What's going on?\" I was thinking, \"I'm not going anywhere, and I don't want him to see me,\" and he said, \"I'm sorry, but you can't take it anymore,\" so I said, \"I'm sorry, but I'm sorry.\"\n",
      "\n",
      "MARK: I'm so sorry, but I don't know what to do.<|endoftext|>\n",
      "STORY: THE HISTORY OF THE BANK OF NEW YORK.<|endoftext|>\n",
      "STORY: A woman with a baby, a baby, and her husband in the car. She had a lot going on, and the car didn't have a lot of power, so she drove to a gas station and got a ride home. The driver was not there, so he drove to her house, where he pulled out the baby and the baby was still alive, but she was not breathing. She was screaming, and the baby was crying because she was scared of what was going on, and she was afraid of being alone with her husband, because he had a baby, and she was afraid of being alone with her husband, so he drove home. He didn't know if he could get her to stop crying, so he started crying and started driving away. She was crying, but the driver was not there to help, so he drove home. He didn't know if he could get the baby to stop crying, so he started crying and started driving away. She was crying, but the driver was not there to help, so he drove home.<|endoftext|>\n",
      "STORY: It's All About the Money, and I'm Getting It\n",
      "\n",
      "I've been working at a small business for the past year, and I've seen a lot of people come up to me and say, \"You know, I've never seen this kind of stuff before,\" but I'm always thinking about it. I'm always thinking about the money and how it affects people, but it's not like I've seen it before. It's just that I'm always thinking about how I can get it back, and I'm always looking for ways to get back to the money.\n",
      "\n",
      "I started this blog in 2011 to share my story of how I lost $100,000 on a car accident, and I've been doing that since then. I'm still trying to figure out how to make money, but I've found that the money can't come back. I'm trying to figure out how I can make money, and if I can't, I'm going to have to find another job to take care of it all.<|endoftext|>\n",
      "STORY: I didn't want to be alone. I was afraid I was being watched, and I was afraid I was being watched, and I was afraid I was being watched, and I was scared I was being watched.\"\n",
      "\n",
      "The man was taken to the hospital and taken to a hospital in a wheelchair, where he died.\n",
      "\n",
      "The man was taken to the hospital in a wheelchair, and taken to a hospital in a wheelchair, and taken to a hospital in a wheelchair, and taken to a hospital in a wheelchair, and then to a hospital in a wheelchair.\n",
      "\n",
      "He died in hospital on Saturday, May 14.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "\"The only thing that makes me sadder is when my father tells me I'm not allowed to have sex with him. I'm afraid he'll punish me if he doesn't. I'm scared that he won't punish me if I don't tell him about my sexual fantasies. I'm afraid that if he does, he will punish me, and he will punish himself for it.\"\n",
      "\n",
      "I'm not sure if I'm being honest or not, so I'm going to keep going.\n",
      "\n",
      "I'm not sure if I'm being honest or not, so I'm going to keep going.\n",
      "\n",
      "I'm not sure if I'm being honest or not, so I'm going to keep going.<|endoftext|>\n",
      "STORY: 'I saw the girl in the bathroom, and she was wearing her hair in a bun, and I thought, 'Oh my god, this girl's going to be a good girl,'\" she said. \"I looked at her, and I said, 'You know, she's a girl, she's a girl, she's a girl, she's going to be great.'\"<|endoftext|>\n",
      "STORY: The Day the Earth Stood Still, The Day The Earth Stood Still\n",
      "\n",
      "\"I don't want to be the only one that doesn't know what happened,\" he said, his voice trembling. \"I want to be the one that gets to know the people who died in this place.\"\n",
      "\n",
      "He looked at his watch, then at the clock on the wall, and then at his watch, his face still red and his eyes still red, and he said, in an angry voice, \"You know what? I'm not gonna lie. I'm not going to lie. I don't know how long this will take, but I'm gonna keep telling you. I'm gonna tell you what happened. I'm gonna tell you what happened. I'm gonna tell you what I know now. I don't care if you think you're stupid, I don't care if you're stupid, I don't know if you're stupid, I don't know if you're stupid. You're stupid, you're stupid, you're dumb, you're stupid.\"\n",
      "\n",
      "The clock stopped ticking, and he looked at his watch, then at the clock on the wall, then at his watch again, then at the clock on the wall again, and he said, \"You know what?\"<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "What is the best way to go about your business?\n",
      "\n",
      "How to make a profit?\n",
      "\n",
      "How to get a good job?\n",
      "\n",
      "What is the most important thing you want to know about your company?\n",
      "\n",
      "What are the best ways to get paid?\n",
      "\n",
      "Why do you think you are the best person in the world?\n",
      "\n",
      "What are the most important things you want to know about your job?\n",
      "\n",
      "What are the most important things you want to know about your family?\n",
      "\n",
      "What do you think about the news about the company?\n",
      "\n",
      "What is your favorite thing about the company?<|endoftext|>\n",
      "STORY: THE LAST DAY OF THE WORLD\n",
      "\n",
      "\"The last day of the world is the last day we'll ever see you,\" she said, looking up at the sky, her eyes locked on the sun. \"You've been here for so long, and now you're going to be here for the rest of your life, you know that.\" She smiled, then turned to look back down at the sky, her eyes widening in shock. \"I don't know why you're here, but I'm here for you, I know you love me, I love you.\" She turned to leave, her voice trembling, and she walked back to the door, leaving her husband behind.<|endoftext|>\n",
      "STORY: What I Learned from my Life in the Church\n",
      "\n",
      "The first thing I learned was how to be a good person. I learned that I was not alone.\n",
      "\n",
      "I learned that my life was not always easy, that my friends and family were not always as good as I thought they were, and that I was not always the best person. I learned to love myself, to live my life in a loving way, to live with the truth, to love my family.\n",
      "\n",
      "I learned that my family was not always my friends, that they didn't always know what I wanted or needed, or what was important, and that my life was not always the way I thought it was supposed to be. I learned that I needed to learn to be myself, not just to live with the truth, but to love my family, to be a good person, and to be a good person for the rest of my life.<|endoftext|>\n",
      "STORY: The Battle Of The Bastion\n",
      "\n",
      "I'm not sure if it's because I'm a fan, or maybe because I'm just bored. But I'm sure I've been waiting for the day that I'll be able to see the final scene of The Battle Of The Bastion.\n",
      "\n",
      "The first scene of the film, \"The Battle Of The Bastion,\" is the final battle in the final battle of the war between humanity and the Machine God. The battle was fought in the final battle of the war between humanity and the Machine God, which was fought in the final battle of the war between humanity and the Machine God. It is a scene that has been haunting the hearts of the people of the world for years, as the war raged on, and I was so glad to see it finally end.\n",
      "\n",
      "I'm glad that the movie is finally coming to an end, but the final battle of this war is not ending. The final battle will be fought in the final battle of humanity, but the final battle will be fought against the Machine God, who has been trying to destroy humanity forever. The final battle will take place on a planet that has never been touched by the machine, but it will be the final battle of humanity, and it is the last battle that will be fought.<|endoftext|>\n",
      "STORY: The Story of the Day - A New Day in History\n",
      "\n",
      "The story of the day is one that has always fascinated me. It is the day I was born and the day I was born again and the day I became a father. It is the time when the world changed and the day I was born was the day I was born again.\n",
      "\n",
      "I was born with the promise of a new life and a new future. I was born with a new family and I was born with the hope that someday I would have a family and that someday I would have a future.\n",
      "\n",
      "The world changed forever. The world changed forever.\n",
      "\n",
      "I have been living my dream for over 20 years and I am proud of that. I am proud of the people that I love, the people that I have loved, the people that are always with me, and the people that I love so much.<|endoftext|>\n",
      "STORY: An old man who was a member of the family of a man who was killed in the line of duty, was found dead in the back seat of his car in the parking lot of the parking lot of his home on the outskirts of the city of St. Petersburg, Russia. He was a member of the family of a man who had been killed in the line of duty, was found dead in the back seat of his car in the parking lot of the parking lot of his home on the outskirts of the city of St. Petersburg, Russia. He was an old man who had been killed in the line of duty, was found dead in the back seat of his car in the parking lot of the parking lot of his home on the outskirts of the city of St. Petersburg, Russia.<|endoftext|>\n",
      "STORY: The Day The Earth Stood Still\n",
      "\n",
      "The day after the meteor shower, the earth was still in a coma, but the meteor shower didn't kill it off. The meteor shower was the last thing on Earth that day. The meteor shower would not last long, and Earth would not be able to keep up. The meteor shower was the only thing on Earth that could keep Earth from being destroyed. The meteor shower was the only thing that could stop the earth from being destroyed, and Earth would be able to keep on going. The meteor shower would last for a few hours, but Earth would not be able to keep on going.\n",
      "\n",
      "The Earth would be able to keep going, but the meteor shower would not last long, and Earth would not be able to keep on going. The meteor shower was the only thing on Earth that would keep Earth from being destroyed, and Earth would not be able to keep on going. The Earth was not going to be destroyed, and the meteor shower was the only thing on Earth that could stop the earth from being destroyed, and Earth would be able to keep on going.\n",
      "\n",
      "The Earth was not going to be destroyed, and the meteor shower would not last long, and Earth would not be able to keep on going.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "The day after the attack, I went to the bathroom and saw the body of my boyfriend, a man I knew from college, lying on the floor of the bathroom. I grabbed my phone and called 911, but he was dead. I didn't know what to do, but I was scared to go back to my dorm room and find him. I didn't know what to do, and I was afraid that he would be dead, so I went back to the bathroom, but the door opened. I saw him lying there in the hallway, blood everywhere. I ran for my life, screaming for help.\n",
      "\n",
      "I woke up the next morning to a strange voice in my head:\n",
      "\n",
      "\"I heard a scream, and I ran for the bathroom. I ran, but he was gone. I ran back to the bathroom, but he wasn't there, and I ran to the bathroom door, but the door was locked. I ran back inside, but he was gone.\"\n",
      "\n",
      "I was shocked, but I didn't know what to do. I ran to the bathroom, but the doors closed and the screams were deafening. I ran to the bathroom door and found him lying on the floor, bleeding from the mouth. I ran to the bathroom door, but the doors closed and the screams were deafening. I ran back inside, but he was gone.<|endoftext|>\n",
      "STORY: HOW MANY OF THE MOST IMPORTANT PEOPLE ARE IN THE WORLD, AND WHY ARE THEY NOT?\n",
      "\n",
      "I have been in this world for a long time, and it's been a very difficult time, but I have always been grateful for the people who have supported me and the people who have supported me in my life. I know that I will never be alone again, and I will always love you all and will never stop loving you, and I will never stop being with you forever, because of you.<|endoftext|>\n",
      "STORY: The Dark One\n",
      "\n",
      "I've never been a fan of the show. The first episode of season two, \"The Dark One\", was the first time I watched it, and I was so excited. The show was so good, and the writers were great, and it was so much fun, and the cast and crew were great. I was really excited about the show, but I had no idea what was happening, so I was so excited to see what was going to happen next. I had no idea how the show would end, so I just sat there and watched the show. It was so fun.\n",
      "\n",
      "I was so excited to see the cast and crew. The show is so great, and I was so excited to see what was going to happen next.\n",
      "\n",
      "I had no idea what was going to happen next, so I just sat there and watched the series.\n",
      "\n",
      "It was so much fun, but I was so excited to see what was going to happen next.\n",
      "\n",
      "I was so excited to see the cast and crew.\n",
      "\n",
      "It's been a while since I've been on a TV show. I was so excited to see what was going to happen next.\n",
      "\n",
      "I was so excited to see what was going to happen next.\n",
      "\n",
      "I was so excited to see the cast and crew.\n",
      "\n",
      "I was so excited to see the cast and crew.\n",
      "\n",
      "I was so excited to see the cast and crew.<|endoftext|>\n",
      "STORY: Why do humans have a brain?\n",
      "\n",
      "I asked myself if I should be a scientist or a doctor, and I was surprised at how many of the answers seemed to contradict one another.\n",
      "\n",
      "I didn't know what to say to the man, who was staring at me with an expression of disbelief. \"Why do you think that you're so stupid?\" he asked. \"You're a genius,\" I told him. \"You know that I'm the only one who knows what you think, and I'm going to explain it to you. You don't have to understand, do you?\"\n",
      "\n",
      "I looked at him for the first time, but he looked away, his face still grimacing. \"You're stupid, aren't you?\" I asked, my eyes widening.\n",
      "\n",
      "He looked at me for a moment before he said, \"I don't think so,\" before he said again. \"You know what I mean, don't you?\"\n",
      "\n",
      "I looked away, my eyes widening as I thought of the last time I'd seen him, and I couldn't help but feel the cold air on my face, as I watched him stare at me for another moment.<|endoftext|>\n",
      "STORY: A LIFE AT A TIME OF THE DEAD\n",
      "\n",
      "\"The story of my life at the time of the death of my mother, my sister, was a story that I had been told many times, and I would never have told it to anyone else, because my sister had died in the same way, and it was not my fault, but my fault, my fault, because my mother had been the person who would have done it to me,\" she said.\n",
      "\n",
      "The story of the life at the time of my mother, my sister, was a story that I had been told many times, and I would never have told it to anyone else, because my sister had died in the same way, and it was not my fault,\" he said.\n",
      "\n",
      "\"I was so happy to see my mother, who was my best friend for the last three years of my life, and I was so proud to see that she was able to live her dream and to be with her family, and I couldn't wait to see her again,\" said his wife, Karen, who has been with him for the last three years.<|endoftext|>\n",
      "STORY: \"THE TURBO\"\n",
      "\n",
      "\"I'm going to go to the doctor,\" said the doctor, \"I want you to get some blood work done. I don't want to have to go to the doctor with you. I don't want to have to see you again.\"\n",
      "\n",
      "The doctor said he would not, \"I don't want to see you again.\"\n",
      "\n",
      "\"I'm going to go to the doctor, and I want you to get some bloodwork done. I don't want to have to see you again.\"<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "The first thing I remember was my mom telling me that I was going to be a girl. She said that I was going to have a baby girl and I had to go with her to a friend's house to have it. I was going to have a baby girl, and my mom was going to take me home and give me the keys to her house, so I was about to go to the bathroom and open the door to see what was going to happen. I looked at the door, but I didn't know what was going on, so I opened it and saw my mom and dad standing in front of the door. I was shocked to see my mother and dad staring blankly at each other, and my dad said, \"Mom, you're not going to let me have your baby girl, are you?\"\n",
      "\n",
      "\"No, Mom, I'm not going to let you have your baby girl,\" my mom said, shaking her head. \"Mom, I'm not going to let you have a baby girl. I'm going to have you, and I want you to be happy.\"<|endoftext|>\n",
      "STORY: The \"Tiny Little Girl\" Story - A New Beginning in the Storytelling Industry\n",
      "\n",
      "The story of the \"little girl\" story began with a story of her parents, who had a baby and were trying to raise their son. She was the only girl in her family. She was the only one who was not a virgin. The story started with her mother telling the story of how her mother had told her that she was a virgin when she had no idea she was pregnant. The mother told the tale of how she had been in the bathroom with a friend and she was suddenly stopped by her boyfriend, who was holding his hand. She told him that he was holding his hand, and he said that he had never touched her before, so she was going to tell him the truth about what happened. The story went on and on, until she was finally stopped by the boyfriend and he told the story of how he had touched her, and she was crying, crying, and he said he would never do that again. The story continued until she was finally stopped by the boyfriend and he said that he had never touched her before and he was sorry, but he had never touched her again and he was going to kill her. The story ended and her parents were gone, and the story continued.<|endoftext|>\n",
      "STORY: The Legend of the Black Rose\n",
      "\n",
      "\"I've been looking for a new job for a long time, but I've never been lucky enough to get one,\" he said. \"I've been living in an apartment in the city for the past year, and I don't know if I'm going to make it.\"\n",
      "\n",
      "He didn't have much choice. \"I don't know if I'll be able to get a job, but I don't know how long it'll take to get there, so I'm not sure if it's going to be long.\"\n",
      "\n",
      "He looked around, then down at a pile of papers, then at the door, then at the desk. \"I'm not sure what to do, but I don't want to be the only one who gets fired,\" he said quietly, his voice cracking.\n",
      "\n",
      "The door swung open and the man walked in with a smile on his face, his hands on his hips and his eyes wide. \"I'm sorry,\" he said, and then he turned and walked away.<|endoftext|>\n",
      "STORY: The Battle of the Bazaar, Part 1: The Battle of the Bazaar, Part 2: The Battle of the Bazaar, Part 3: The Battle of the Bazaar, Part 4: The Battle of the Bazaar<|endoftext|>\n",
      "STORY: 'What's wrong with me?'\n",
      "\n",
      "\"I was sitting in a car with my friends and we were driving down a road when I noticed that the driver was driving at a high rate of speed. I was shocked, I was shocked, I looked around and saw the driver had a red light, I looked back at the red light and saw that I was in fact driving drunk,\" he said.\n",
      "\n",
      "\"I looked at the car and saw the driver had a red light and then he started yelling at me and started driving at me,\" said Mr. Boudreault, who was driving with friends when he saw the driver pull out a gun and fire at Mr. Boudreault.\n",
      "\n",
      "Mr. Boudreault said the driver pulled out a gun and fired at him. Mr. Boudreault said he was hit in the head with the gun and he was taken to a hospital where he later died.\n",
      "\n",
      "Mr. Boudreault was arrested on suspicion of second-degree murder.\n",
      "\n",
      "Mr. Boudreault was charged with second-degree murder and was released on a $100,000 bond.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "I was sitting at my desk, reading a letter, and my wife, who was sitting next to me, asked me to read it.\n",
      "\n",
      "I read it, and I couldn't believe it.\n",
      "\n",
      "\"I'm sorry,\" I said.\n",
      "\n",
      "\"No, no, I'm not,\" she said.\n",
      "\n",
      "I read it again and again.\n",
      "\n",
      "\"I'm so sorry,\" I said.\n",
      "\n",
      "\"No, no, no, no, no,\" she said. \"I'm so sorry,\" she said. \"I'm so sorry.\"\n",
      "\n",
      "I was so sorry.\n",
      "\n",
      "\"I didn't mean to hurt you, I didn't mean to hurt you,\" I said.\n",
      "\n",
      "I was so sorry.\n",
      "\n",
      "\"I don't know how you're feeling, I don't know how you're feeling, I don't know how I'm feeling, I don't know if you're feeling better or worse,\" I said.\n",
      "\n",
      "I was so sorry.\n",
      "\n",
      "\"I don't want to hurt you, I just want you to know I love you, I just want you to know that I love you, I love you, and I'm sorry,\" I said.\n",
      "\n",
      "I was so sorry.\n",
      "\n",
      "I was so sorry.\n",
      "\n",
      "I didn't want you to know that I love you.<|endoftext|>\n",
      "STORY: The world is a mess. The world is a mess because the people are not getting what they deserve, and the world is a mess because of the government. The world is a mess because of the people who are not doing their job. The world is a mess because of the government. The world is a mess because of the people who are not doing their jobs. The world is a mess because of the government.<|endoftext|>\n",
      "STORY: We have lost a great friend. We lost a friend, and we are going to lose him.\n",
      "\n",
      "We lost a great friend, and we are going to lose him.\n",
      "\n",
      "I have been waiting for this day for years. I have been waiting for this day for years. I have been waiting for this moment, and now I am finally here.\n",
      "\n",
      "I am waiting for this moment. I have been waiting for this moment for years, and now I am finally here.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "I was in the middle of my first night of school when I heard a loud bang. I ran to the door and saw my friend standing in the hallway, his head was covered in blood. He was wearing only a white t-shirt, jeans and a black jacket. I grabbed his hand, pulled it out and ran. I ran to the bathroom and ran into the bathroom. He was bleeding from his mouth, his face was covered by blood and his hands were shaking, I grabbed my friend's arm and ran.\n",
      "\n",
      "I was in the middle of a bathroom with the blood pouring from his mouth, I grabbed his hand and ran. I ran into the hallway, I saw him lying on the floor, his eyes were wide open, blood was pouring down his back. I ran, I ran, I ran, I screamed, and ran back to my friend's room.\n",
      "\n",
      "I ran, I ran, I screamed, I ran, I screamed and ran back to the bathroom.\n",
      "\n",
      "I was in the middle of my first night of school when I heard a loud bang, I grabbed his hand, pulled it out and ran. I ran, I ran, I ran. I ran, I ran, I screamed, I ran, I screamed, I ran, I ran, I screamed and ran back to my friend's room.<|endoftext|>\n",
      "STORY:  *     * I'm not sure if I can get my head around this.       * I'm not sure if I'm ready for the day, but I can't help but think about the pain I feel, and I'm not sure if I'm ready for it.    I'm not sure if I'm ready for this, but I'm not sure if I'm ready to go to work.      *  I'm not sure if I'm ready to go to sleep.      *    * I'm not sure if I'm ready for the day, but I can't help but think about the pain I feel, and I am not sure if I'm ready to go to sleep.       * I'm not sure if I'm ready to go to sleep...       <|endoftext|>\n",
      "STORY: The story of a girl who lost her virginity to her boyfriend.<|endoftext|>\n",
      "STORY: I have learned to love my life. I have learned to love myself. I am not a bad person, and my friends and family are not good people. But I am not the bad person I thought I was, and I have learned to love myself, too.<|endoftext|>\n",
      "STORY: A new way to get the most from your favorite movies, TV shows, music, and games!\n",
      "\n",
      "The new way to get the most from your favorite movies, TV shows, music, and games.\n",
      "\n",
      "The new way to get the most from your favorite movies, TV shows, music, and games.\n",
      "\n",
      "The new way to get the most from your favorite movies, TV shows, music, and games.\n",
      "\n",
      "\n",
      "*Please note that this app requires the latest version of Adobe Flash Player to play.<|endoftext|>\n",
      "STORY: A Mummy, The Mummy, The Mummy.\n",
      "\n",
      "I was sitting on a bench, looking at the clock on my phone, watching the clock go by. It was 9:45 p.m., and the clock on the wall was still on, and the clock on my computer screen was ticking. The Mummy was in the middle of his birthday party, and I was sitting there, watching the clock tick down.\n",
      "\n",
      "I was sitting on my bench, staring at the clock, waiting for him to come home.\n",
      "\n",
      "\"Hello,\" I said, \"I'm here to talk to you about something, but I can't talk to you about it right now because of the clock on the wall. I'm going to call you, but please don't worry, I'll be sure to talk to you later. Just call me at any time, I'll be sure to get you home safely.\"<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "The first thing that comes to mind is the fact that the world was a mess before the apocalypse, and it is now. I am not going to tell you how many people died and how few survived, but I am going to tell you that the world was a mess before the apocalypse. I am going to tell you that there was no hope, no peace. The only thing that was left was a few thousand of our friends, family, and loved ones who had to die, and we are going to be forever changed. I will be there to help you. I am going to tell you that you will be the one to stop the apocalypse. I am going to tell you that you can save the world. I am going to tell you how to save your family. I am going to tell you that you will never have to worry about your loved ones, and you are going to never have to worry about your family. I will tell you that you will be able to save the world. I am going to tell you that you can be happy and healthy, and you will be the one who will save the world from the evil that has been taking us all to the brink.\n",
      "\n",
      "So, here we go, the first of many, many, many, many stories about the apocalypse, and it is going to get better, and better, and better.<|endoftext|>\n",
      "STORY: HOW I GOT HERE\n",
      "\n",
      "I was about to leave my house when I heard someone shout something. \"Hey, hey, you're here!\" I looked up, but I didn't see him. \"I'm not coming back,\" he said, his voice trembling.\n",
      "\n",
      "I turned and saw him standing in front of the house, staring straight ahead, his hands clasped behind his back as he looked back at me. \"What the hell are you doing here?\"\n",
      "\n",
      "I looked back at him, then at him again and he looked back at me again. \"I don't want you here. I don't want to hurt you,\" he said. \"I just want you here.\"<|endoftext|>\n",
      "STORY: A man's life changed forever. He was the only person alive who knew how to talk to his dead wife and kids. He was the only one who could talk about the pain of being a father to the dead, and he was the only one who understood that he could not live alone. He was not alone in his grief, he was alone in his grief, he was the only one who knew how to live with his grief. He was the only person who could talk about the pain of being a father to his dead wife and kids. He was the only one who understood that he could not live alone.<|endoftext|>\n",
      "STORY: \"I'm not going to be able to sleep tonight, and I don't want to sleep alone. It's not like we have to talk about this, but I'm going to have to go get a new pair of pants, and I'm going to have to go to bed early. I don't want to wake up at 5:00 in the morning and I don't want to wake up at 6:00 in the morning and I don't want to wake up in the middle of the night.\"<|endoftext|>\n",
      "STORY: I have seen the world through the lens of my own eyes. I see the world from the outside. I see the world from the inside out. I see the world from the outside in my head. I see the world from the inside out in my heart.\"<|endoftext|>\n",
      "STORY: Why The Hell Did The Church Get So Angry? The church was not happy with its actions, so it decided to shut down the Church of Jesus Christ of Latter-day Saints (Mormons) for good and set up its own church. The Mormons were not pleased with the church's actions and decided to go back to their old ways. The church was now run by a man who wanted to destroy the Mormon Church. The church's founder, Joseph Smith, was killed by a mob of angry mob members, but the church was not destroyed. The church was rebuilt, but the church was not destroyed. The church was not destroyed because of the church's leadership, but the church was destroyed because of the church's leadership.<|endoftext|>\n",
      "STORY: The Story of the First World War.\n",
      "\n",
      "The war was not over, but the world was still fighting, and the war was not over.\n",
      "\n",
      "The war was over, and the people were fighting for their lives.\n",
      "\n",
      "The war was over, and the people were fighting for the future of the world.\n",
      "\n",
      "But the war was not over, and it was only because of the people who were willing to stand up to the Nazis.\n",
      "\n",
      "The war was never over.\n",
      "\n",
      "The war was never over.\n",
      "\n",
      "The war was never over.\n",
      "\n",
      "And it was only because of the people who fought, the people who fought for the people.<|endoftext|>\n",
      "STORY: How long do you have to wait before you get your job?\n",
      "\n",
      "JAMES: I'm not sure, but I've had enough time to figure it out. I've got to get my job done before I can start getting my job back.\n",
      "\n",
      "JAMES: What do you mean?\n",
      "\n",
      "JAMES: I'm not sure, but I've had enough time to figure it out. I've got to get my job done before I can start getting my job back. I'm sure I'm not the only person who's got to get their job done.\n",
      "\n",
      "JAMES: What are you talking about?\n",
      "\n",
      "JAMES: I'm sorry, but I'm not sure what to do with you. I'm sure you don't want me to see you again, and I'm sure I don't want to see you again either.\n",
      "\n",
      "JAMES: What do you mean, James? You're not going to see me again?\n",
      "\n",
      "JAMES: I'm sorry, James. I'm sorry for the pain and frustration that you've caused. I'm sure I can do it, and I'm sure I can do it without you.<|endoftext|>\n",
      "STORY: I was just trying to get my hands off of the car, and when I got out of my car, the driver of the car started yelling, \"I'm going to kill you!\" I ran to him, but he was holding my hand. I ran back to get my hands off him, he pulled me over, and he started yelling at me to get back into the car, \"I'm going to kill you!\" I ran back to get my hands off him, he pulled me over, and he started yelling at me to get back into the car, \"I'm going to kill you!\" I ran to him, but he was holding my hand. I ran back to get my hands off of him, he pulled me over, and he started yelling at me to get back into the car, \"I'm going to kill you!\" I ran to him, but he was holding my hand. I run back to get my hands off of him, he pulled me over, and he started yelling at me to get back into the car, \"I'm going to kill you!\"<|endoftext|>\n",
      "STORY: \"A Long Time Ago\"\n",
      "\n",
      "The story of a man named Jack and his family who was kidnapped by aliens and brought back to Earth by his family, who are trying to escape from the planet's gravity well, is told in this short, but very touching, story of the story of a family that has been lost forever. Written by John Lott, the author of the best selling \"A Long Time Ago\" series, \"The Last of the Aliens\" is a story of the family's journey to find a new home in the universe, but the journey is not complete until the last of them, a young boy, has been abducted by aliens.<|endoftext|>\n",
      "STORY:  I was in a room with a guy who had just started to talk about his new book.  I was sitting in front of him, looking down at the book and thinking about the book, and then suddenly, I saw him.  He looked at me with wide eyes and said,  \"I know you're going to be reading it, so I thought I'd ask you to take a look at the cover.  I'm not sure if I'm getting the right answer, but I know you'll be able to tell me what you think.  I'm sure you'll find a lot of interesting things, and I'm sure you'll be able to tell me what I'm thinking.\"  I looked at him, and he looked at me with a wide smile.  \"I'm sorry, but I don't know what to say to you, so I'm going to ask you to take a look at this book.  I'm sure you'll find a lot of interesting things, and I'm sure you'll be able to tell me what I'm thinking.\"<|endoftext|>\n",
      "STORY: What happened to the girl in the bathroom?        I was sitting on the toilet, and I heard the girl's voice, and then I saw her crying and then I saw her crying again and I saw the girl's face.                        \n",
      "I looked up, and then I saw the girl's face, and then I saw that she was crying.                      \n",
      "I looked up, and then I saw the girl's face, and then I saw the girl's face again, and then I saw the girl's face again, and I saw the girl's face again.                 <|endoftext|>\n",
      "STORY: The Secret History of the United States, by John C. Calhoun\n",
      "\n",
      "In this fascinating book, Calhoun explores the relationship of the United States with its allies in the Pacific. He explores how the U.S. government's role was to protect and defend the interests of the people of the Pacific, and how the United States was to protect and defend the interests of the world's most powerful nation.\n",
      "\n",
      "The book is a great read for anyone interested in history, politics and geopolitics, and it will be a pleasure reading for anyone interested in the history of the U.S. and the world.\n",
      "\n",
      "Read the book now!<|endoftext|>\n",
      "STORY: We are the first of many people who have been diagnosed with autism, and we are the first to be able to tell you that we are not just the first to be diagnosed with the disease; we have been the first to experience it. We are not alone, and we are the first to have a cure. The world will never know if we are truly the first to be diagnosed with the disease. We are the first to be able to tell you that we are not just the first to be diagnosed with the disease; we have been the first to experience it. We are not alone, and we are the first to have a cure.<|endoftext|>\n",
      "STORY: Why I Hate the Police.        The police are the only ones I know who are not afraid to talk about it.       I'm afraid to talk about it, because they are afraid to talk about it because it is embarrassing.<|endoftext|>\n",
      "STORY: The New Normal, The New Normal.\n",
      "\n",
      "\"I don't know if I can say it, but I'm glad you were here, and glad I was able to see the world through your eyes. It's been so much fun, and I can't wait to see what you have to offer.\"\n",
      "\n",
      "I nodded. I had to say something, but I had to keep it to myself, so I kept my eyes open, and I could hear the familiar voice in my ears, whispering something to me as the sun set, \"I'm sorry, I was just wondering what you were thinking when you said you wanted to go back to the world of magic, and I don't know how you felt about it, but I know that I can't stop you from leaving this world, and I'm going to leave it behind. I'm going to go find the people you've been waiting for, and I'm going to leave you alone, so you don't have to wait around for me.\"<|endoftext|>\n",
      "STORY: What does it mean to be a man?\n",
      "\n",
      "I'm not sure if it means anything to me. I've always been a man, but I'm not sure if that means anything.\n",
      "\n",
      "I don't know how I feel about this. I don't want to be the guy I am now. I want to be the guy I always wanted to be, the guy I always wanted to be.\n",
      "\n",
      "I want to be the man that I always wanted to be, the guy that I always wanted to be.\n",
      "\n",
      "I don't want to be the guy who always wanted to be, the guy I always wanted to be, the guy that I always wanted to be.<|endoftext|>\n",
      "STORY: When I heard about this book I was so excited. I was going to read it, but it wasn't going to be my first book, so I was really excited. I read it in the morning, and then my husband and I were going to bed and I started to cry. I was so excited to read this and it was so beautiful. I was so sad, I couldn't wait to read it again.<|endoftext|>\n",
      "STORY: A man who has been missing since June has been found alive in a remote area of the country's north-eastern border, authorities said on Saturday.\n",
      "\n",
      "The man, who was not named, was last seen in the area of the town of Kowalski, about 20 kilometres from the border with Turkey. He was last seen in a car in the village of Kowalski in northern Baku province on Saturday, the Kurdistan Regional Government (KRG) news agency reported.\n",
      "\n",
      "The man was last seen in a car in the village of Kowalski, near the border with Turkey.\n",
      "\n",
      "\"He was last seen in the area of a village in the village of Kowalski, about 20 kilometres from the border with Turkey,\" the Kurdistan Regional Government (KRG) news agency reported.\n",
      "\n",
      "\"He was last seen in the area of a village in the village of Kowalski in the village of Baku in northern Baku province on Saturday evening,\" the news agency added.<|endoftext|>\n",
      "STORY: You are not alone. You know it. I am alone, and I am alone with you, and I know it. I know that you are my only hope, my only hope. You have always been my friend and I have always wanted to be with you. But I know that you have been wrong about that. You have always been wrong about that. You know that I am not alone in this world. You know that I have never been alone in my life. You know that I have always been with your family, and that I have never been alone with you. You know I have always wanted to be with you, and you know that my life is not over, that I am not alone, that I am not alone with you, and that I will always be with you. You know I am not alone in this world. You know that my family and my friends and my friends and my family will never be together. You know that I will never be alone, that my life will never end. You know that I will never be alone.<|endoftext|>\n",
      "STORY: Why do the people who are the victims of the attacks in the city want to kill me? I am the only one who can save them. I have been in the city for the last three months, and I have been waiting for my chance. I am the only one who can save them. I have been waiting for this moment for three years, and now I have finally arrived. I am here.<|endoftext|>\n",
      "STORY: I just found this guy, I'm going to call him, and I just wanted to tell him what I saw and I was just so excited to see what he looked like, I was just so excited. I just wanted to tell him that I saw this guy and that he was a real guy. He looked like he was in his late 30s, and I was so happy he had seen me, he was just so happy, he was so happy to see what he looked like.\"\n",
      "\n",
      "\"I was just so excited to see what he had done, he was such an amazing guy,\" said Kelli, who was in her 20s at the time. \"I'm just so glad he had the chance to be here, I just want him to be here forever.\"<|endoftext|>\n",
      "STORY: I am writing to you, Mr. Speaker, to express my deepest condolences to the families and friends of the two victims of the shooting at a church in Sutherland Springs, Texas, this past weekend. The shooting was a senseless act of hate and bigotry, and I am deeply saddened to learn of the tragic loss of a young woman who was the first person to call for help. The tragedy of this tragedy will not be forgotten. I know the family members of those who were in the church, and I am praying that they can be comforted by their prayers and understanding that the shooter was not a member of the church. I know that the church was not a place of worship for the people of Sutherland Springs, Texas, and I know that the shooter was not an active member of the church community. I know that I will never forget this day, but I am praying to God that we all will be safe, that we will be able to pray together, that we will never have to go back to the church and see this terrible tragedy again. I am praying that the family of those killed in this senseless act will be able to pray together, that the church community will continue to be strong, and that we all will continue to live our lives in harmony. Thank you, Mr. Speaker.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "\"I was just trying to get my hands dirty. It was like my body was being pulled apart by my own hands, and I couldn't move. I had to get out of the car and get my hands off of the car seat and I couldn't move, so I started crying.\"\n",
      "\n",
      "\"I didn't know what to do, so I just kept crying, trying not to cry, trying not to think about it, trying not to think about the pain, trying to think of how I could do it, and I couldn't,\" said the woman, who asked not to be named. \"I couldn't even move, I was so scared, I couldn't even move, and I just kept crying, trying not to cry, trying not to think about it, trying to think of how I could do it, and I couldn't.\"<|endoftext|>\n",
      "STORY: It's not a good idea to kill a child, and it doesn't make me feel good.  It's not a good idea to kill a child, and it doesn't make me feeling good.  I'm going to kill myself, and I'm going to die alone, and I'm not going to be able to get out of this place, and I'm going to die alone.\"<|endoftext|>\n",
      "STORY:  I was sitting on my couch, reading a book.  I looked down at the pages, wondering what was going on.  Then I saw my friend, who was sitting at the other end of the couch, staring at me with a sad expression.  I turned to look at her and she smiled, and then she turned back to me and looked at me, and then I looked back at the page, and I said, \"I'm not sure what happened.\"<|endoftext|>\n",
      "STORY: 'The Man Who Laughs' - The Man Who Laughs'\n",
      "\n",
      "The Man Who Laughs is a comedy show that premiered at the New York Comedy Festival in September 2013. It was the first comedy show to air on Broadway, and it was the first show to feature a man who laughed.\n",
      "\n",
      "The show has become one of the most talked about shows of the year, and it was a hit. The show has been nominated for three Emmys and has won two Golden Globe Awards, including Best Comedy Show and Best Musical.<|endoftext|>\n",
      "STORY: I don't think I'm the only person who has seen this movie, but I'm not sure if it's the only one,\" he said.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "In the beginning, the world was a dark place, but the darkness was beginning to fade. The world had changed, but the darkness had not. The darkness had not stopped. The darkness was beginning to fade, but it would take a long time before we could see it, and the darkness will not be gone.<|endoftext|>\n",
      "STORY: \"The Best of Both Worlds\" - A new book by writer/director, writer/director, and producer, \"The Best of Both Worlds\" explores the life and work of a young man in the United States, living with his family and friends, working as a freelance journalist, and living with the world. Written by writer/director, director, and producer, \"The Best of Both Worlds\" explores the life and work of a young man in the U.S., living with his family and friends, working as a freelance journalist, and living with the world.<|endoftext|>\n",
      "STORY: We're back in our apartment building, and we're having a hard time keeping up with the news, because our apartment has been flooded with people. I'm trying to figure out why, and I'm trying to figure out how to get my roommates to come out of the apartment and get some food, but I'm afraid they're not coming out. I'm trying to figure out how I'm going to get them to stay, because I'm afraid they're going to kill me. I'm trying not to think about it, and I'm trying to think about the other people I know who are in the apartment, and the people who have been hurt. I'm afraid I'm going to be killed, and if I get out, I'm going to be the only one who can save them.<|endoftext|>\n",
      "STORY: The Day That Changed the World    The day that changed the world.   I was a teenager when my parents divorced and my dad was a doctor.   My mother and father were both doctors.   I remember my father saying, \"I'm going to be the best doctor in the world, I don't want to be a doctor anymore.\"   I was so happy, I didn't even think about it.   I was just a kid.   I didn't know what to do with myself.  I was just going to live my life, and then my parents divorced, and my dad was a nurse and I was going to live my life with my mother and my dad.<|endoftext|>\n",
      "STORY: How a man named \"Teddy\" was killed by a man who had no idea what was happening.\n",
      "\n",
      "I was at the house with my brother and my mother when the news broke. I was in tears and my mother said to me, \"I don't understand how he can do that to someone who is not a stranger.\"\n",
      "\n",
      "I said, \"You don't understand, Teddy.\"\n",
      "\n",
      "\"He was a stranger, he was a stranger,\" my mother said. \"I don't understand how he could do that to anyone.\"\n",
      "\n",
      "\"He's not a stranger,\" Teddy said. \"He didn't even know how to talk to anyone, he just said, 'I'm not going to tell anyone, I'm going to tell you.' \"\n",
      "\n",
      "I was shocked, I thought to myself, \"I don't know why I should be angry with him, but he didn't even know how to talk to anyone.\"\n",
      "\n",
      "Teddy was the only person I knew who could understand how to talk to someone, I thought to myself, \"I don't understand how he can talk to someone who is not a stranger.\"<|endoftext|>\n",
      "STORY: \"Truck\" (The first of two movies in the series, \"Truck\" was released in Japan in 1997)<|endoftext|>\n",
      "STORY: My first book was a book I wrote for my sister. She loved me and I loved her so I decided to write it. It was a book that I had never read and I loved it so much. I was so excited to read it and I was so glad I did! I love the story and the story is so beautiful!<|endoftext|>\n",
      "STORY: What is it about the world that makes you want to die?                                         \n",
      "\n",
      "I'm not sure what I'm doing here but I'm not sure what I'm doing here.                                  \n",
      "\n",
      "I'm not sure what I'm doing here but I'm not sure if I'm going to get out.                           \n",
      "\n",
      "I'm not sure what I'm doing here but I'm not sure if I'm going to be able to get out of here.                       <|endoftext|>\n",
      "STORY: Why did I get into the game, and why am I doing it?\n",
      "\n",
      "JONATHAN: I'm a kid, and I'm not a big fan of the idea of playing the game. I'm not a huge fan of the idea, but it just doesn't make sense to play it.\n",
      "\n",
      "JONATHAN: I'm not sure why, because it's not fun. It's not fun to play.\n",
      "\n",
      "JONATHAN: I don't know. Maybe it was the fact that I was playing the game that made me want to quit, or maybe the fact that I was playing the game that made me want to quit, or maybe the fact that I didn't want to play the game at all. I don't know. I don't know. Maybe I'm just a kid.\n",
      "\n",
      "JONATHAN: I don't know. I'm not sure. Maybe I'm just an idiot. Maybe I'm just playing it because I'm bored. Maybe I'm just not a huge fan of the idea, or maybe I'm just not sure what I want to do with my life. I don't know.\n",
      "\n",
      "(The game is played.)<|endoftext|>\n",
      "STORY:  In a small room, a man sits on the floor, looking at the floor.   He is dressed in black and white and his hair was tied up in bunches.   His eyes were closed, but his voice was calm and clear.  The man's eyes were closed, but he looked at me with a blank expression.   He said,   \"I'm not going anywhere.\"<|endoftext|>\n",
      "STORY: The World of the Dead\n",
      "\n",
      "The world of the dead was once a world of darkness and darkness, but it has been replaced by a world of darkness and darkness. The world of the dead is the only place in this world where people can see and feel pain and fear and the pain of death. It is a world where people are trapped, trapped in a world of darkness, where people have been killed and the world is filled with people who are not dead, and where there is only darkness and pain. The world of the dead is the world of the dead where people have been killed and the pain of death is the only thing that people can see and feel.\n",
      "\n",
      "In this world, the only thing that people can see and feel is the pain of death. The only thing that people can feel in this world is the pain of death, and that is why it is so difficult to find people who can see and feel pain and pain.\n",
      "\n",
      "In this story, the world of the dead is the only place where people can see and feel pain. The world of the dead is the place where people can feel fear and pain, and the pain of death is the only thing that people can see and feel.<|endoftext|>\n",
      "STORY: A young man named James is a student in a college town in the middle of nowhere. He's been living with his parents for a few years now, but he has no idea what he's doing. The school is a small, quiet place with a few people, but he has no idea what he's going to do when the time comes. He's been living with his parents, and now, he's been living in his room alone for the past few weeks. He's been alone for the past few months, and now, he's going to have to go to the bathroom, because the bathroom door has closed, and he can't see his parents, so he's going to need to go to the bathroom. He's been living alone for about a month, and now, he's going to have to go to the bathroom to get his parents' help, because the bathroom door has closed, and he can't see his parents, so he has to go to the bathroom to get the help. James is going to have to go to the bathroom to get help, because the bathroom door has closed, and he can't see the parents, so he's going to have to go to the bathroom.<|endoftext|>\n",
      "STORY: 'Truck, I'm going to get out,' I heard a woman say to her friend. I was sitting on the couch, and the woman said, 'I'm going to take care of you, and then you're going to be okay.' I was sitting in front of her, and the woman was holding my hand and said, 'I'm sorry, but I can't help but feel guilty for taking you so long.' I said, 'I'm not going to let you go. I'm going to take care of your body, and then I'm going to take care of your mind, and then you're going to be okay,' and she was crying and saying, 'I'm going to take care of you,' and I'm going to take care of my mind, and then I'm going to take care of my mind.' I said, 'I know you're going to have a lot of trouble with that, but I'm going to help you with that.' She said, 'I don't know what you're going through, but I know you're going to have to be okay, and then I'm going to help you.'<|endoftext|>\n",
      "STORY: \"I didn't know what to do. It was like I had been shot in the back of the head.\"\n",
      "\n",
      "I'm not going to tell you what to do. I'm not going to tell you how to get to the hospital. I'm not going to tell you how to get out of the hospital. I'm not going to tell you how to get to the hospital. I'm not going to tell you how to get to the hospital.\n",
      "\n",
      "I'm going to tell you what to do. I'm going to tell you how to get to the hospital.\n",
      "\n",
      "I'm going to tell you how to get to the hospital.\n",
      "\n",
      "I'm going to tell you how to get to the hospital.\n",
      "\n",
      "I'm going to tell you how to get to the hospital.\n",
      "\n",
      "I'm not going to tell you how to get to the hospital. I'm not going to tell you how to get to the hospital.<|endoftext|>\n",
      "STORY: An Evening with the Stars\n",
      "\n",
      "I was sitting in the living room, reading a book. The light on my laptop was dim, and the words on the pages were blank. I looked at the clock, and the words \"I'm sorry\" were on the pages. \"You can't read this, I'm sorry, you're too young,\" the words were written across the pages, but the words were still on the pages, and I couldn't see them. \"I'm so sorry, but you can't read this, I'm not going to read you, and you can't read me,\" the words were written across my lips. I looked at the clock again, and it was 11:00 AM, the last time I was awake in the morning. \"You can't read this,\" I said, and I was done, and I was going home.<|endoftext|>\n",
      "STORY: The first time I saw this movie, I was sitting in the living room of the house watching a movie, and I saw this guy, a guy I knew from high school, he was wearing a baseball cap and a baseball hat, and he said to me, \"Hey, look at this picture of you, you're the one who got hit in the face by a car,\" and I said, \"What?\" He looked at me and said, \"You're the one who got hit in the face by a car,\" and I said, \"I'm not going to tell anyone,\" and he said, \"No one will ever know, and I'm going to tell them,\" and he said, \"You're going to have to pay me, and I'll take your car, and then I'll take you home.\"<|endoftext|>\n",
      "STORY: It's been a long, hard day for us. We have been working hard, but it is not over, and we are still waiting for the day that we will be able to return home to our families and friends.\n",
      "\n",
      "We are not sure what to make of the news that the family has been taken from them, but we are sure that they will be reunited with their loved ones and will be able to return home to their families. We are grateful to the family for their support and hope that they can return home to their loved ones.<|endoftext|>\n",
      "STORY: The World Without You\n",
      "\n",
      "The first time you see the World Without You, you'll be transported into a world of darkness and despair. It's the first time you've ever seen a human being alive, and the first time you'll see a human being in a position of power and responsibility. The first thing you'll see are the people you love, and the people you hate. The world without you is a dark place, but the people around you will be your friends and family.\n",
      "\n",
      "You will find yourself alone, alone in a world of darkness, and you will find yourself trapped inside a world where you are powerless. You will find yourself in the world of darkness, and you will be trapped inside a world where you are not alone, but you will find yourself alone in a world where you are not alone, and you will find yourself trapped inside a world where your loved ones are dead and your loved ones are alive.<|endoftext|>\n",
      "STORY: HOW to create a beautiful, unique and beautiful world.<|endoftext|>\n",
      "STORY: A PRAIRIE, A RIVER, A RIVER. I'm a woman, a man. I'm a woman who lives alone, and I'm a woman who has to live with her own pain. I've been living alone for over a year, and I'm still here, and I'm going to be alone forever. I'm going to die, and I'm going to live with this pain, this sadness, this pain, and this pain, and this pain, and I'm going to live forever with the pain, this sadness, the pain, the pain, the sadness, and this pain, and I'm going to live forever, and I'm going to be alone forever. I'm going to be alone forever.<|endoftext|>\n",
      "STORY: \"A MOMENT OF LOVE, A MOMENT of DEPRESSION\"\n",
      "\n",
      "I've always loved the way my mom used to talk to me, and it was always about the things that she said and did, but now, I'm getting a new sense of the world around me, and I'm getting to see the world from my mom's point of view. I'm getting closer to the truth, and I'm getting to see the world from her point of view, and I'm getting to see her from the perspective of a person who has never met her before, and who is not afraid to tell her the truth. I'm getting to hear the voices of people who know me, and the voices of people who have never met me, and I'm getting to hear the stories of the people who are still alive, who are still alive to hear them, and I'm getting to know the people who are still alive, who are still alive to hear them, and I'm getting to hear the stories of people who are still alive, who are still alive, and I'm getting to hear the stories of people who are still alive, people who still alive to hear them, and we're getting closer to that truth.<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "\"I am a woman, a woman who has been married for 40 years. I have never been able to find love, I have never been able to get married, and now I'm in a situation where I am not sure I can get my life together. I have to get out of this place, get married, and I have to find my own place. I have to get married and I am not going to be alone, I am not going to have to live in a place where I can not get my life together.\"<|endoftext|>\n",
      "STORY: How to get to the airport safely and safely\n",
      "\n",
      "The airport was packed with passengers waiting in line for a flight from London.\n",
      "\n",
      "\"I was in the back seat of a taxi, I heard a woman screaming,\" said one passenger, who asked not to be named. \"I was in the back seat of a taxi, and she was screaming at the top of her lungs.\"\n",
      "\n",
      "The passenger said she was in the back seat of a car, but when the driver asked her to leave, she refused and ran away, she said.\n",
      "\n",
      "\"I thought it was my fault, I didn't want her to see me, she didn't want to see me,\" she added.<|endoftext|>\n",
      "STORY: \"It's a good day to go to the gym. I'm feeling better, I'm getting better, I'm getting stronger.\"\n",
      "\n",
      "The next morning I went back to my room and sat in my chair, looking at the clock on my computer. I had been working out for a few hours, but my body felt like it was starting to feel a bit sluggish. I had been doing a lot of stretching and I felt like I was starting to lose some of my strength, and I felt like I needed to go back to the gym to recover. I started to feel a little tired, but I was feeling better. I started going to the gym, and I was feeling pretty good.\n",
      "\n",
      "\"I know you're going to be feeling better,\" I said, \"but I don't know if I can get you back to the gym. I'm going to have to go to bed, and I want to wake you up early.\"\n",
      "\n",
      "I was going to go to bed, and I didn't want anyone to see my body. I wanted my body, my body, and I didn't want to let anyone see my body because I wanted to get better and get better at my job and my life. I wanted my body, my body, my body. I wanted my body to heal and I wanted to go back to work, but I didn't know how.<|endoftext|>\n",
      "STORY: What the hell is wrong with you? I don't know what's bothering you, but I'm going to go home. I'm going to get some sleep and get you some food.<|endoftext|>\n",
      "STORY: The Last of Us: The First Time You Were Alone\n",
      "\n",
      "\"It was a long day,\" she said, \"but I had to stay up late to do my homework and watch the movie, so I was just going to sleep.\"\n",
      "\n",
      "\"I was so happy,\" I said with a grin, \"that I thought I was going to be able to go back to school and do some of my homework, but it turned out that my parents had been telling me to stay at home and watch movies, so I didn't want to go.\"\n",
      "\n",
      "\"I'm sorry about that,\" she said, \"I just wanted to go home and watch some movies.\"\n",
      "\n",
      "\"I'm sorry about that too,\" I said, \"I'm sorry about the fact that you're going to be my best friend, but I'm going to go get some sleep and get ready for my next class.\"<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "We have been waiting for the last few days for a new release of this amazing game. We are excited to share with you the news of our new release of The Legend of Zelda: Breath of the Wild. We have been waiting patiently since the last time you played the game, but we are excited for you to experience the new Zelda experience.\n",
      "\n",
      "We are thrilled to announce that we have finally released our newest release, The Legend of Zelda Breath of the Wild, on PC, PlayStation 4 and Xbox One, and will be releasing it for the first time on November 14th, 2017. The game will have an all new story, a new story mode, and new characters to explore, and it will be a great game for everyone who loves Zelda.\n",
      "\n",
      "The game will be released on November 14th, 2017, and we will be sharing more information about the game with the world, so stay tuned! We hope to see you soon!<|endoftext|>\n",
      "STORY: \"The Night of the Living Dead\" - \"I'm going to kill myself.\"\n",
      "\n",
      "\n",
      "The night of the living dead was one of the most memorable moments I've ever had. The night of the living dead, the night that I was supposed to be dead. It was a night that I was supposed to be dead, and I was supposed to be alive. I didn't know what to do, and the only thing I knew that I could do was to go home. I didn't know how, I just didn't know how to live. I didn't know how to live. I didn't know how I was going to survive, I just didn't know how to live.\n",
      "\n",
      "\n",
      "I woke up the next morning, and I was in my bed. I was lying on my side, looking at the clock, wondering what I had to do to get back to sleep. I was going to die, and I didn't know if I would be able to get up to go to sleep, or if I would die alone, and I couldn't even get to sleep. I was in a terrible dream, and I was going to be dead. I was not going to die alone, and I was not going to die alone with my life on the line. I was not going to be alone, and I was not going to die alone with my life on the line.<|endoftext|>\n",
      "STORY: My first day in the office, I was in my office, and I was wearing my office clothes, and my boss was standing there, looking at me with a wide smile, and he asked, \"What's going on?\" I said, \"It was a prank, and it worked, but it was so embarrassing, so embarrassing. I'm going to call the police, and I'm going to tell them what happened, and then I'm going to tell them that my boss has been arrested for disorderly conduct and that he's not allowed to leave the office, so I'm going to call my boss.\" He said, \"You know what, you're going to have to call the police, and I'm going to tell them that I don't want you to be in the office for this, so I'm going to tell the police what happened.\" I was shocked. \"I don't want to be in the office, I don't want to be alone,\" I said. He said, \"You're going to call the cops, and I'm going to tell them what happened, and then I'm going to tell the cops what I'm going to do with you.\"<|endoftext|>\n",
      "STORY: \"I'm a girl, I'm a girl.\"\n",
      "\n",
      "\"I'm a girl, I'm a girl,\" I said, my voice breaking, \"I'm a girl, I'm a girl.\"\n",
      "\n",
      "\"I'm a girl,\" I said, my voice breaking, \"I'm a girl.\"<|endoftext|>\n",
      "STORY:\n",
      "\n",
      "I am an adult, so I have no idea what I'm doing with my life right now, and I don't know if I can do anything to change it. I am so tired of living in this world that I am trying not to let it get to me and to live with it, and I don't want to let it get to me. It's not going to get to me until I can get my mind off my life.\n",
      "\n",
      "I have been living with my parents for the past year or so, and I don't know if I can get out of it. My mother has told me she wants to move to another country, and she wants to see me grow up, but I don't know what I can do to help her. I don't know what I can do, but if it doesn't help her, I don't know what will.\n",
      "\n",
      "I am so tired of living in this world that I am trying not to let it get to me, and I don't know if I can do anything to change it.<|endoftext|>\n",
      "STORY: How to start a new job.\n",
      "\n",
      "\"I was working at a local restaurant and when I got home, I saw a man standing next to me and he was wearing a black shirt and black pants. I asked him what he was doing and he said he was trying to get some money for his family, so I walked up and grabbed my wallet and walked over to where the man was holding a gun and pointed it at him. I grabbed his gun and started shooting at him. He was dead,\" said the woman.\n",
      "\n",
      "The man was taken to the hospital and later died, according to the police report.\n",
      "\n",
      "The man's wife, who is a police officer in the area, said the man had a history of mental illness.\n",
      "\n",
      "\"He was very angry, he was upset, he was upset that I was going to kill him, and he was angry that I didn't take him to a doctor because he was afraid that I was going to kill him. He was a good guy, he was a good person, he was a good person, he was a good person, he was a good person,\" said her husband, Mark.\n",
      "\n",
      "The man's name has not been released. He was not identified.<|endoftext|>\n",
      "STORY: A young girl, who was in her late teens, was abducted by her parents. She was abducted from the house, and her parents were able to escape. The girl was found in the woods, and her mother was able to get out of the house, but the kidnappers took her to a remote location, where they tortured her and raped her. She is now in the custody of a local family, and she has never spoken to her mother. She has no friends, no friends to speak of, and no one to talk to. The kidnappers are trying to kill her, but her mother is not happy about it. The kidnappers are trying to get her to leave the house, but her mother is afraid of them. She is afraid that the kidnappers will kill her if she doesn't leave, and that the kidnappers will kill the family if she doesn't leave. She is afraid that the kidnappers will kill her, but she will never leave the house. The kidnappers are trying to kill her, but she will never leave the house. The kidnappers are trying to kill her, but she will never leave the house. The kidnappers are trying to kill her, and she will never leave.<|endoftext|>\n",
      "STORY: The Great Gatsby\n",
      "\n",
      "I'm a little bit nervous about this one because I'm not sure what I'm going to say to the guy who was the first to tell me about it. I'm sure he'll tell me that I'm a bit of an idiot for thinking I'm going to be a great writer, but I'm not sure how I feel about that. I'm not really sure if I'm going to be able to write a book, or if I'm going to be able to write a book about the Great Gatsby. I don't know how to answer that question.<|endoftext|>\n",
      "STORY: The End of the World.\n",
      "\n",
      "The story of a man who was born into a world where everything he knew was gone and who had been born into a world where everything he loved was gone.\n",
      "\n",
      "The story of a man who has been born into a world where everything he loved is gone.\n",
      "\n",
      "The story of a man who has been born into a world where everything he loves is gone.<|endoftext|>\n",
      "STORY: \"I was just trying to get my kids to school,\" said the boy. \"I didn't know what to expect.\"\n",
      "\n",
      "\"I didn't know how to get them to school,\" said his mother, who had recently moved to the area to help with the family's expenses, \"and I didn't know how to get my kids to school.\"\n",
      "\n",
      "The boy was taken to a hospital for treatment of a broken arm, but doctors said he would be OK.\n",
      "\n",
      "\"He's been in the hospital for about two weeks now, and he's been in the hospital for two hours,\" said his mother, who had recently moved back to her home in the city to help pay the bills.\n",
      "\n",
      "\"I'm just trying to get him to school,\" said the boy's father, who had been with him for the past few months.\n",
      "\n",
      "\"I don't know if he'll be OK, but I'm trying to get my kids to school,\" the father said, his eyes wide.\n",
      "\n",
      "\"I'm trying to make sure that he doesn't go to school again,\" said the boy's mother, who had recently moved back to the city to help with the family's expenses, \"but I'm trying to get him to school, too.\"<|endoftext|>\n",
      "STORY: The Day After The Day After The Day After the Day After The Day After\n",
      "\n",
      "I was sitting on the couch watching the TV when a woman walked up and said, \"Hey, you're going to be here for dinner tonight, and I'm going to be here for your dinner tonight.\"\n",
      "\n",
      "\"I know,\" she said.\n",
      "\n",
      "I looked at her, and I smiled. She smiled back. I walked over and sat down next to her, then sat next to her and said, \"You know, I'm going to be late for dinner tonight, and I'm going to be late for your dinner tonight.\"\n",
      "\n",
      "I sat there, thinking about the night before and how much I loved her. I loved her so much. She was so sweet, so kind and kind to me. I wanted nothing less from her and I wanted to do everything in my power to help her. I wanted to make sure she would be safe and happy, but she was so sweet and kind to me. She was my best friend, and I wanted her to be safe. I wanted her to be happy. I wanted her to be happy, so that I wouldn't have to worry about her getting sick, and I wanted her to be happy, so that she could have the best life possible.\n",
      "\n",
      "I was so happy, and so happy to have her.<|endoftext|>\n",
      "STORY: \"What was the first thing I saw when I was in college?\" I asked my roommate. \"It was a huge, huge, huge, huge, huge, massive, huge, huge, massive, huge,\" he said. He looked at me, then at me, then at me again. \"I saw a big, big, big, huge, huge, massive, huge, massive, giant, huge, huge, huge, giant.\"<|endoftext|>\n",
      "STORY: 'Why does the universe have such a big problem with our existence?'\n",
      "\n",
      "'I'm not sure what the answer is, but I think it is the same thing as the universe has a huge problem with its own existence,' he said.<|endoftext|>\n",
      "STORY: A New York City Police Department Investigation\n",
      "\n",
      "A man was shot and killed by police after he tried to break into the police department's office building, according to the New York Daily News. The man was shot and killed by officers who arrived at about 1:15 a.m., the newspaper reported. The shooting was captured on surveillance video. The man was taken to Advocate Christ Medical Center in critical condition. The police department said the man was a suspect in a robbery, but the suspect is still at large.\n",
      "\n",
      "The New York Daily News reported that a woman was killed and another person was wounded in the shooting. The victim was taken to Advocate Christ, where he was pronounced dead, according to the newspaper.<|endoftext|>\n",
      "STORY: The Final Day\n",
      "\n",
      "\"I'm not gonna lie, it was pretty amazing,\" said Kaitlyn. \"I was just so excited, and I was so happy to see my friends and family. I'm so happy that we're getting to see the world through this new lens of life. I'm just so excited to be able to share my story with the world, and I hope everyone will be as happy as I am.\"\n",
      "\n",
      "Kaitlyn and her friends are currently traveling to Japan, where she's currently working on a project with a Japanese company. The project, called The Final Day, was started to help people who are struggling with depression, anxiety, and other mental health problems. The Final Day is an initiative to help people find the answers they want in life, and the goal is that it will help people find their way through their lives, whether it's a new job, new job, new friends, new relationships, new relationships with family, new friends, or just being with someone.<|endoftext|>\n",
      "STORY: The Story of the Day\n",
      "\n",
      "\"I've always loved the way you talk to your kids,\" said my mom, \"but I'm always afraid to tell them that you're not the best at it.\"\n",
      "\n",
      "I looked down at my daughter's face, my face still wet from the cold, \"I'm sorry, I'm sorry,\" she said, \"I didn't mean to hurt you.\"\n",
      "\n",
      "\"I didn't mean to,\" I said, \"I just didn't want to hurt you.\"\n",
      "\n",
      "\"I'm not sure what you meant,\" said the older woman, \"I'm sure it was because you're a little too cute to be my daughter.\"\n",
      "\n",
      "She smiled, and I felt my heart pound in my chest, \"Don't worry,\" I said. \"Just don't worry about me.\"\n",
      "\n",
      "I looked down at my daughter, and she looked at me, and she looked at me, her eyes still wet from the cold, \"I know you're not the best at it, but I'm sure it was because you're a little too cute to be my daughter,\" she said, \"You know what, you know I love you, you know what? I know I love you, and it makes me happy to be around you, and I'm sure you're happy to know that I'm not the one that hurt you.\"<|endoftext|>\n",
      "STORY: MARY, THE LITTLE BOSS, AND THE BOSS'S BOSS\n",
      "\n",
      "MARY: I'm not sure if I can tell you how I feel about this story, but I'm glad you're enjoying it.\n",
      "\n",
      "I'm sorry, but I'm not sure if you're enjoying this story.\n",
      "\n",
      "You know what, I'm not sure what to tell you, but you're going to be happy to hear that I'm not the only one who thinks that.\n",
      "\n",
      "MARY: You're right, I'm not the only one.\n",
      "\n",
      "I'm sure that you're not the only one who thinks I'm a liar.\n",
      "\n",
      "I'm not the only one who thought that, and I'm not the only one who thinks that.\n",
      "\n",
      "You know what, I'm not sure if you're enjoying this story, but I'm glad you're enjoying it.<|endoftext|>\n",
      "STORY: THE NEW STORY\n",
      "\n",
      "\"I don't want to be a part of the story. I'm not going to be the person who tells the story,\" he said, \"I want to tell my story. It's not about the story, it's about the people who are going to tell the story. I want to tell my story to them.\"\n",
      "\n",
      "The story begins with the young man who is now in his early 20s and has just started to walk his dog.\n",
      "\n",
      "The man who is now the man to save the dog, he is now in his early 30s and has just begun to walk his dog. The dog is a mix of white, black and gray, but the man has been walking for years.\n",
      "\n",
      "\"I'm not going anywhere,\" he said as he started walking toward the front of the house. \"I'm just going to walk.\"<|endoftext|>\n",
      "STORY: I'm looking for someone who is willing to help me with this, but I'm afraid that if I don't, I'll be left with no one.\"\n",
      "\n",
      "\"I'm afraid that I'm not someone who can help you,\" she said.\n",
      "\n",
      "\"I'm afraid I'm not someone who can help you,\" he said. \"You can always find someone else to help you, and I know you'll always be with me.\"\n",
      "\n",
      "\"I don't know who I am,\" she said. \"I'm sorry, I'm not sure if I'm the only one with you, but if I don't find someone, I'm afraid I'll be leaving you.\"<|endoftext|>\n",
      "STORY: A BORING, BORING, BORING...I'm going to take a break from the game, and I'm going to take a walk, so please, don't worry about the kids. They're not going anywhere, so I don't want to get into trouble. They're going to be okay.\"\n",
      "\n",
      "\n",
      "I'm going to take a walk, and I'm going to take a walk, and then I'm going to take a walk, and I'm going to take a walk, and then I'm going to take a walk, and then I'm going to go home and I'm going to go back to my room.\n",
      "\n",
      "\n",
      "(pause, looking at the clock on the wall)\n",
      "\n",
      "\n",
      "(pause, looking at the clock on the wall)\n",
      "\n",
      "\n",
      "(pause)\n",
      "\n",
      "\n",
      "(pause)\n",
      "\n",
      "\n",
      "(pause)\n",
      "\n",
      "\n",
      "(pause)\n",
      "\n",
      "\n",
      "I'm not going anywhere, and I'm not going anywhere, and I'm not going anywhere, and I'm not going anywhere. I don't care, I don't care, I don't care.<|endoftext|>\n",
      "STORY: How the New York Times and the New Yorker have changed the way we think about the news, the news, and the news media.\n",
      "\n",
      "JAMES MARTIN: I'm James M. Martins, and I'm the author of the book \"The New Yorker.\"\n",
      "\n",
      "AMY GOODMAN: James Martins is a professor of journalism, and he's been a journalist for more than 20 years, but he was born in the United Kingdom, in the United States. He was raised on the streets of New York City, and he was raised in the suburbs of New Jersey, where he grew up in the suburbs of Newark.\n",
      "\n",
      "JAMES MARTIN: I grew up in the suburbs of New York, and I grew up in the suburbs of New Jersey.\n",
      "\n",
      "JAMES MARTIN: And I was raised in the suburbs of Newark and I was raised in a place where the media was so powerful.\n",
      "\n",
      "AMY GOODMAN: James Martins, thank you very much for being with us from the United States.\n",
      "\n",
      "JAMES MARTIN: Thank you.<|endoftext|>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:27\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_EPOCH = 4\n",
    "#Generating the stories\n",
    "models_folder = \"GPT2_trained_models\"\n",
    "model_path = os.path.join(models_folder, f\"gpt2_small_story_4.pt\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "stories_output_file_path = f'generated_4_stories.txt'\n",
    "model.eval()\n",
    "if os.path.exists(stories_output_file_path):\n",
    "    os.remove(stories_output_file_path)\n",
    "\n",
    "story_num = 0\n",
    "max_lenght= 300\n",
    "with torch.no_grad():\n",
    "    for story_indx in range(500):\n",
    "        #print(\"hi\")\n",
    "        story_finished = False\n",
    "        cur_ids = torch.tensor(tokenizer.encode(\"STORY:\")).unsqueeze(0).to(device)\n",
    "        for i in range(max_lenght):\n",
    "            outputs = model(cur_ids,labels=cur_ids)\n",
    "            loss, logits = outputs[:2]\n",
    "            softmax_logits = torch.softmax(logits[0,-1],dim=0)\n",
    "            if i < 3:\n",
    "                n = 20\n",
    "            else:\n",
    "                n = 3\n",
    "            next_token_id = choose_best_n(softmax_logits.to('cpu').numpy(), n=n)\n",
    "            cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) \n",
    "            #print(cur_ids)\n",
    "            #story_finished = True\n",
    "            #print(next_token_id)\n",
    "            #print(\"TE: \",tokenizer.encode('<|endoftext|>'))\n",
    "            if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
    "                story_finished = True\n",
    "                break\n",
    "        if story_finished:\n",
    "            story_num += 1\n",
    "            output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "            output_text = tokenizer.decode(output_list)\n",
    "            #print(\"im here\")\n",
    "            with open(stories_output_file_path, 'a') as f:\n",
    "                f.write(f\"{output_text} \\n\\n\")\n",
    "                print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d6556-050f-4d6c-8d4f-8c732e473619",
   "metadata": {},
   "source": [
    "**Note:** we paused the kernel because the largest time that the generator take for generating data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3574b4d-e318-47bb-85d7-8820b4a94e3c",
   "metadata": {},
   "source": [
    "### Part3 BERT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd672154-8703-47c1-8eb2-eac2b390be9a",
   "metadata": {},
   "source": [
    "##### #Sentiment classification task with BERT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a652a6-45cc-46b0-a353-698d0e8327b7",
   "metadata": {},
   "source": [
    "DataSet : https://nijianmo.github.io/amazon/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d26215-b954-471a-8406-57347e8322af",
   "metadata": {},
   "source": [
    "<h2>About BERT base model (uncased):</h2> \n",
    "\n",
    "Pretrained model on English language using a masked language modeling (MLM) objective. This model is uncased: **it does not make a difference between english and English.**\n",
    "\n",
    "<h3>Disclaimer:</h3>The team releasing BERT did not write a model card for this model so this model card has been written by the Hugging Face team.\n",
    "\n",
    "<h3>Model description:</h3>\n",
    "BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labeling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was pretrained with two objectives:\n",
    "\n",
    "**1-Masked language modeling (MLM):**\n",
    "taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally masks the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
    "\n",
    "**2-Next sentence prediction (NSP):**\n",
    "the models concatenates two masked sentences as inputs during pretraining. Sometimes they correspond to sentences that were next to each other in the original text, sometimes not. The model then has to predict if the two sentences were following each other or not.\n",
    "This way, the model learns an inner representation of the English language that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled sentences, for instance, you can train a standard classifier using the features produced by the BERT model as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c7ce845-e4c0-4b34-ad99-a697af81027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import os \n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c41e8dd-3343-4f98-864b-e6b62cfdbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Video games reviews data set and preprocess it\n",
    "def load_amazon_data(num_lines=None):\n",
    "    VG_path = os.path.join(\"_data\", 'Video_Games_5.json')\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open(VG_path, 'r', encoding=\"UTF-8\") as j_file:\n",
    "        # Process each line as a separate JSON object\n",
    "        texts = []\n",
    "        labels = []\n",
    "        for i, line in enumerate(j_file):\n",
    "            if num_lines is not None and i >= num_lines:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                json_object = json.loads(line)\n",
    "                \n",
    "                # Safely extract the values using .get()\n",
    "                overall = json_object.get('overall')\n",
    "                review_text = json_object.get('reviewText', '')\n",
    "                summary = json_object.get('summary', '')\n",
    "                \n",
    "                # Append summary to reviewText\n",
    "                modified_review_text = f\"{review_text} {summary}\"\n",
    "                \n",
    "                # Store the modified object\n",
    "                texts.append(modified_review_text)\n",
    "                labels.append(int(overall)-1)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error in line: {line}\\nError: {e}\")\n",
    "    \n",
    "    return texts, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01129b5b-4b7a-42ab-9aff-3ed64d093e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts,labels = load_amazon_data(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a5e324e-26f1-4d0b-8576-e544c1e8d4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00de04bf-c240-4fa0-a0c8-f49b12c6e258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64ae39fe-91c7-4945-a610-c0de64ac03be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788df54d-ebf5-4f94-a9b5-963785327c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a custom dataset class for text classification\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a19613e7-ef2d-41ea-b7d5-a342e6bbdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build our customer BERT classifier\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            x = self.dropout(pooled_output)\n",
    "            logits = self.fc(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a11605e-c24b-47b4-9baf-10ccce27626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the train() function\n",
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d25cf5a-06dd-44aa-9372-ea31f4621bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    class_report = classification_report(actual_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(actual_labels, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    return accuracy, class_report, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8deddae6-f325-4ac0-9606-316c6c699b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build our prediction method\n",
    "def predict_overall(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return preds.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e220bc3-f8d5-4f1f-a66c-47c577317595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model’s parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 5\n",
    "max_length = 200\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "995226ab-2af6-4366-a783-fa724e26e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and splitting the data.\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aea3d3fc-cc1e-49b5-9d4d-b66363d31df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize tokenizer, dataset, and data loader\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "00d06b6c-702f-4d7f-81da-fffbddf21d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the device and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b739a70-f92f-49df-8537-26e4d0cb7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate,no_deprecation_warning=True)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ab4e911-27fc-4c5d-825e-6ddd49cb2f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Validation Accuracy: 0.7867\n",
      "Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62        16\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.44      0.22      0.30        18\n",
      "           3       0.42      0.33      0.37        42\n",
      "           4       0.86      0.96      0.91       217\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.47      0.43      0.44       300\n",
      "weighted avg       0.74      0.79      0.76       300\n",
      "\n",
      "F1-score:  0.7589478576615831\n",
      "Epoch 2/5\n",
      "tensor(0.6563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Validation Accuracy: 0.7933\n",
      "Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67        16\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.67      0.22      0.33        18\n",
      "           3       0.42      0.36      0.38        42\n",
      "           4       0.86      0.96      0.91       217\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.52      0.45      0.46       300\n",
      "weighted avg       0.76      0.79      0.77       300\n",
      "\n",
      "F1-score:  0.7664031650057851\n",
      "Epoch 3/5\n",
      "tensor(0.7997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Validation Accuracy: 0.7833\n",
      "Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67        16\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.67      0.33      0.44        18\n",
      "           3       0.40      0.55      0.46        42\n",
      "           4       0.90      0.90      0.90       217\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.52      0.49      0.49       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "F1-score:  0.7781233769566333\n",
      "Epoch 4/5\n",
      "tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Validation Accuracy: 0.7833\n",
      "Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        16\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.60      0.33      0.43        18\n",
      "           3       0.40      0.55      0.46        42\n",
      "           4       0.90      0.90      0.90       217\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.51      0.48      0.49       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "F1-score:  0.7785067262486617\n",
      "Epoch 5/5\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Validation Accuracy: 0.7833\n",
      "Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        16\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.60      0.33      0.43        18\n",
      "           3       0.40      0.55      0.46        42\n",
      "           4       0.90      0.90      0.90       217\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.51      0.48      0.49       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "F1-score:  0.7785067262486617\n",
      "CPU times: total: 27min 17s\n",
      "Wall time: 1h 28min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report, f1 = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Training report: \",report)\n",
    "    print(\"F1-score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd5af77d-d2f0-471e-8709-34d92ffd0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "#torch.save(model.state_dict(), \"bert_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cee1dc9f-ed3f-4e0a-9107-a91354f2d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GodofWar 4 was great and I really enjoyed the performances of the game.\n",
      "Predicted overall: 5\n"
     ]
    }
   ],
   "source": [
    "#Evaluating our model’s performance\n",
    "# Test overall prediction\n",
    "test_text = \"GodofWar 4 was great and I really enjoyed the performances of the game.\"\n",
    "overall = predict_overall(test_text, model, tokenizer, device) + 1 \n",
    "print(\"GodofWar 4 was great and I really enjoyed the performances of the game.\")\n",
    "print(f\"Predicted overall: {overall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda27660-3142-41ea-b9aa-bd0f38b4514d",
   "metadata": {},
   "source": [
    "## #Conclusion:\n",
    "The pre-trained BERT model has revolutionized natural language processing by significantly improving performance in tasks like question answering, sentiment analysis, and text classification. Its bidirectional context understanding and transfer learning capabilities make it highly effective and versatile, enabling efficient fine-tuning for specific tasks. However, BERT models are computationally intensive and can be challenging to deploy in resource-constrained environments. Despite these limitations, BERT has set a new standard in NLP, with ongoing research aimed at enhancing its efficiency and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec3139-7630-440e-a8be-298466ba277d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
